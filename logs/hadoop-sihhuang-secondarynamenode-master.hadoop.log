2015-10-19 00:49:00,948 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 00:49:00,969 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 00:49:03,114 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 00:49:03,292 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 00:49:03,292 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 00:49:03,702 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /root/hadoop/hadoop-tmp/dfs/namesecondary does not exist
2015-10-19 00:49:03,704 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop/hadoop-tmp/dfs/namesecondary is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:967)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:243)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
2015-10-19 00:49:03,707 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2015-10-19 00:49:03,708 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-19 01:21:34,172 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 01:21:34,196 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 01:21:36,457 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 01:21:36,634 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 01:21:36,634 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 01:21:37,038 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /root/hadoop/hadoop-tmp/dfs/namesecondary does not exist
2015-10-19 01:21:37,041 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop/hadoop-tmp/dfs/namesecondary is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:967)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:243)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
2015-10-19 01:21:37,044 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2015-10-19 01:21:37,045 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 01:26:08,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 01:26:08,761 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 01:26:11,048 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 01:26:11,230 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 01:26:11,230 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 01:26:11,631 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /root/hadoop/hadoop-tmp/dfs/namesecondary does not exist
2015-10-19 01:26:11,633 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop/hadoop-tmp/dfs/namesecondary is in an inconsistent state: checkpoint directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(SecondaryNameNode.java:967)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:243)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
2015-10-19 01:26:11,636 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2015-10-19 01:26:11,637 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 01:40:06,174 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 01:40:06,195 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 01:40:08,370 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 01:40:08,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 01:40:08,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 01:40:08,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary/in_use.lock acquired by nodename 5598@master.hadoop
2015-10-19 01:40:08,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 01:40:09,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 01:40:09,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 01:40:09,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 01:40:09,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 01:40:09
2015-10-19 01:40:09,046 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 01:40:09,046 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 01:40:09,047 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 01:40:09,047 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 01:40:09,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 01:40:09,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 01:40:09,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 01:40:09,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 01:40:09,923 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 01:40:09,923 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 01:40:09,923 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 01:40:09,924 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 01:40:09,924 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 01:40:09,954 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 01:40:09,954 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 01:40:09,966 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 01:40:09,966 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 01:40:09,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 01:40:09,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 01:40:09,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 01:40:09,974 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 01:40:09,974 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 01:40:09,974 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 01:40:09,999 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 01:40:09,999 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 01:40:10,137 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 01:40:10,148 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 01:40:10,173 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 01:40:10,180 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 01:40:10,180 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 01:40:10,180 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 01:40:10,217 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 01:40:10,217 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 01:40:11,371 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 01:40:11,371 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 01:40:11,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 01:40:11,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 01:45:11,750 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 01:45:12,048 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 01:45:12,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 01:45:12,715 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 01:45:13,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.11s at 0.00 KB/s
2015-10-19 01:45:13,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 355 bytes.
2015-10-19 01:45:13,424 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 01:45:13,435 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 01:45:13,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003609529 size 0 bytes.
2015-10-19 01:45:13,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-19 01:45:13,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 01:45:13,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary/current/fsimage_0000000000000000000
2015-10-19 01:45:13,528 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 01:45:13,535 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 01:45:13,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2015-10-19 01:45:13,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2015-10-19 01:45:13,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 01:45:13,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/sihhuang/hadoop/hadoop-tmp/dfs/namesecondary
2015-10-19 01:45:13,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.03 seconds
2015-10-19 01:45:13,659 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-19 02:11:14,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:15,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:16,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:17,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:18,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:19,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:20,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:21,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:22,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:23,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:11:23,854 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 17 more
2015-10-19 02:11:25,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 02:11:25,740 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 02:13:14,040 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 02:13:14,061 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 02:13:16,243 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 02:13:16,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 02:13:16,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 02:13:16,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 7868@master.hadoop
2015-10-19 02:13:16,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 02:13:16,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 02:13:16,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 02:13:16,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 02:13:16,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 02:13:16
2015-10-19 02:13:16,877 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 02:13:16,877 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:13:16,878 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 02:13:16,878 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 02:13:16,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 02:13:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 02:13:16,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 02:13:16,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 02:13:16,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 02:13:16,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 02:13:16,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 02:13:17,282 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 02:13:17,282 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:13:17,282 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 02:13:17,282 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 02:13:17,283 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 02:13:17,298 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 02:13:17,298 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:13:17,298 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 02:13:17,298 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 02:13:17,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 02:13:17,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 02:13:17,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 02:13:17,302 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 02:13:17,302 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 02:13:17,302 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 02:13:17,315 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 02:13:17,316 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 02:13:17,382 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 02:13:17,386 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 02:13:17,397 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 02:13:17,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 02:13:17,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 02:13:17,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 02:13:17,419 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 02:13:17,419 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 02:13:18,540 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 02:13:18,540 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 02:13:18,557 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 02:13:18,557 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 02:14:18,763 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 02:14:19,048 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 02:14:19,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=2&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 02:14:19,719 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 02:14:20,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-10-19 02:14:20,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 355 bytes.
2015-10-19 02:14:20,689 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3&endTxId=7&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 02:14:20,711 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 73142.86 KB/s
2015-10-19 02:14:20,711 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000007_0000000000005356795 size 0 bytes.
2015-10-19 02:14:20,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=8&endTxId=9&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 02:14:20,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 02:14:20,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000008-0000000000000000009_0000000000005356817 size 0 bytes.
2015-10-19 02:14:20,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-19 02:14:20,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 02:14:20,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000002
2015-10-19 02:14:20,798 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 02:14:20,814 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-19 02:14:20,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000007 expecting start txid #3
2015-10-19 02:14:20,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000007
2015-10-19 02:14:20,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000007 of size 1048576 edits # 5 loaded in 0 seconds
2015-10-19 02:14:20,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009 expecting start txid #8
2015-10-19 02:14:20,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009
2015-10-19 02:14:20,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 02:14:21,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary
2015-10-19 02:14:21,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 9 to namenode at http://localhost:50070 in 0.03 seconds
2015-10-19 02:14:21,049 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 02:18:40,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 02:18:40,634 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 02:25:23,249 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 02:25:23,276 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 02:25:25,419 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 02:25:25,601 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 02:25:25,601 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 02:25:26,012 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 1565@master.hadoop
2015-10-19 02:25:26,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 02:25:26,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 02:25:26,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 02:25:26,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 02:25:26,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 02:25:26
2015-10-19 02:25:26,328 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 02:25:26,328 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:25:26,330 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 02:25:26,330 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 02:25:26,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 02:25:26,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 02:25:26,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 02:25:26,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 02:25:26,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 02:25:26,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 02:25:26,936 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 02:25:26,936 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:25:26,936 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 02:25:26,936 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 02:25:26,938 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 02:25:26,971 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 02:25:26,971 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:25:26,971 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 02:25:26,971 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 02:25:26,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 02:25:26,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 02:25:26,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 02:25:26,975 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 02:25:26,976 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 02:25:26,976 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 02:25:27,006 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 02:25:27,006 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 02:25:27,141 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 02:25:27,145 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 02:25:27,176 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 02:25:27,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 02:25:27,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 02:25:27,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 02:25:27,218 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 02:25:27,218 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 02:25:28,016 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 02:25:28,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 02:25:28,032 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 02:25:28,032 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 02:26:29,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:30,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:31,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:32,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:33,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:34,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:35,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:36,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:37,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:38,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 02:26:38,079 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 02:26:38,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 02:26:38,597 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 02:28:23,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 02:28:23,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 02:28:25,390 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 02:28:25,569 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 02:28:25,569 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 02:28:25,962 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 2957@master.hadoop
2015-10-19 02:28:26,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 02:28:26,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 02:28:26,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 02:28:26,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 02:28:26,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 02:28:26
2015-10-19 02:28:26,265 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 02:28:26,265 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:28:26,267 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 02:28:26,267 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 02:28:26,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 02:28:26,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 02:28:26,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 02:28:26,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 02:28:26,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 02:28:26,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 02:28:26,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 02:28:26,783 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 02:28:26,783 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:28:26,783 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 02:28:26,783 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 02:28:26,784 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 02:28:26,818 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 02:28:26,818 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 02:28:26,819 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 02:28:26,819 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 02:28:26,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 02:28:26,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 02:28:26,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 02:28:26,829 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 02:28:26,829 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 02:28:26,829 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 02:28:26,854 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 02:28:26,854 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 02:28:26,993 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 02:28:27,004 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 02:28:27,030 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 02:28:27,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 02:28:27,033 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 02:28:27,033 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 02:28:27,074 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 02:28:27,074 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 02:28:28,085 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 02:28:28,085 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 02:28:28,101 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 02:28:28,101 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 03:14:42,167 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 03:14:42,169 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 03:18:11,445 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 03:18:11,465 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 03:18:13,629 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 03:18:13,808 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 03:18:13,808 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 03:18:14,207 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 4707@master.hadoop
2015-10-19 03:18:14,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 03:18:14,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 03:18:14,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 03:18:14,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 03:18:14,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 03:18:14
2015-10-19 03:18:14,520 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 03:18:14,520 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:18:14,521 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 03:18:14,521 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 03:18:14,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 03:18:14,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 03:18:14,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 03:18:14,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 03:18:14,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 03:18:14,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 03:18:15,342 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 03:18:15,342 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:18:15,342 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 03:18:15,343 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 03:18:15,343 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 03:18:15,372 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 03:18:15,372 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:18:15,373 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 03:18:15,373 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 03:18:15,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 03:18:15,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 03:18:15,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 03:18:15,385 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 03:18:15,385 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 03:18:15,385 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 03:18:15,411 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 03:18:15,411 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 03:18:15,549 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 03:18:15,561 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 03:18:15,582 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 03:18:15,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 03:18:15,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 03:18:15,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 03:18:15,627 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 03:18:15,627 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 03:18:16,650 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 03:18:16,651 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 03:18:16,667 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 03:18:16,667 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 03:19:16,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 03:19:17,121 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 03:19:17,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=12&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 03:19:17,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 03:19:18,775 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-19 03:19:18,776 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000012 size 627 bytes.
2015-10-19 03:19:18,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=13&endTxId=14&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 03:19:18,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 03:19:18,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000013-0000000000000000014_0000000000003629633 size 0 bytes.
2015-10-19 03:19:18,822 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 5 INodes.
2015-10-19 03:19:18,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 03:19:18,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 12 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000012
2015-10-19 03:19:18,870 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 03:19:18,886 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 03:19:18,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014 expecting start txid #13
2015-10-19 03:19:18,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014
2015-10-19 03:19:18,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 03:19:18,973 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 12
2015-10-19 03:19:18,974 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2015-10-19 03:19:18,974 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000009, cpktTxId=0000000000000000009)
2015-10-19 03:19:19,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 14 to namenode at http://master.hadoop:50070 in 0.03 seconds
2015-10-19 03:19:19,014 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 03:26:19,766 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 03:26:19,768 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 03:27:09,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 03:27:09,236 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 03:27:11,378 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 03:27:11,553 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 03:27:11,553 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 03:27:11,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 6396@master.hadoop
2015-10-19 03:27:12,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 03:27:12,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 03:27:12,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 03:27:12,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 03:27:12,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 03:27:12
2015-10-19 03:27:12,251 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 03:27:12,251 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:27:12,252 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 03:27:12,253 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 03:27:12,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 03:27:12,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 03:27:12,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 03:27:12,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 03:27:12,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 03:27:12,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 03:27:12,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 03:27:12,706 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 03:27:12,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:27:12,707 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 03:27:12,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 03:27:12,708 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 03:27:12,738 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 03:27:12,738 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 03:27:12,739 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 03:27:12,739 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 03:27:12,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 03:27:12,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 03:27:12,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 03:27:12,749 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 03:27:12,749 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 03:27:12,749 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 03:27:12,771 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 03:27:12,771 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 03:27:12,916 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 03:27:12,926 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 03:27:12,951 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 03:27:12,959 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 03:27:12,959 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 03:27:12,959 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 03:27:12,995 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 03:27:12,996 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 03:27:13,974 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 03:27:13,975 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 03:27:13,991 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 03:27:13,991 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 03:28:14,285 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 03:28:14,529 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 03:28:15,069 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=14&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 03:28:15,195 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 03:28:16,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-19 03:28:16,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000014 size 627 bytes.
2015-10-19 03:28:16,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=15&endTxId=15&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 03:28:16,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 93090.91 KB/s
2015-10-19 03:28:16,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000015-0000000000000000015_0000000000004167039 size 0 bytes.
2015-10-19 03:28:16,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=16&endTxId=17&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 03:28:16,206 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 03:28:16,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000016-0000000000000000017_0000000000004167054 size 0 bytes.
2015-10-19 03:28:16,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 5 INodes.
2015-10-19 03:28:16,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 03:28:16,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 14 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000014
2015-10-19 03:28:16,309 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 03:28:16,324 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-19 03:28:16,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000015 expecting start txid #15
2015-10-19 03:28:16,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000015
2015-10-19 03:28:16,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000015 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-19 03:28:16,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017 expecting start txid #16
2015-10-19 03:28:16,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017
2015-10-19 03:28:16,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 03:28:16,450 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 14
2015-10-19 03:28:16,450 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2015-10-19 03:28:16,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 17 to namenode at http://master.hadoop:50070 in 0.042 seconds
2015-10-19 03:28:16,503 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 04:28:16,960 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 04:28:16,961 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=18&endTxId=19&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 04:28:17,006 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2015-10-19 04:28:17,006 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000018-0000000000000000019_0000000000007767812 size 0 bytes.
2015-10-19 04:28:17,006 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 04:28:17,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019 expecting start txid #18
2015-10-19 04:28:17,007 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019
2015-10-19 04:28:17,007 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 04:28:17,031 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 17
2015-10-19 04:28:17,032 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2015-10-19 04:28:17,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 19 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-19 04:28:17,048 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 05:28:17,461 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 05:28:17,462 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=20&endTxId=21&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 05:28:17,466 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 05:28:17,466 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000020-0000000000000000021_0000000000011368312 size 0 bytes.
2015-10-19 05:28:17,467 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 05:28:17,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021 expecting start txid #20
2015-10-19 05:28:17,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021
2015-10-19 05:28:17,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 05:28:17,475 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 19
2015-10-19 05:28:17,475 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000017, cpktTxId=0000000000000000017)
2015-10-19 05:28:17,492 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 21 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-19 05:28:17,492 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 06:28:17,910 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 06:28:17,911 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=22&endTxId=23&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 06:28:17,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 06:28:17,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000022-0000000000000000023_0000000000014968761 size 0 bytes.
2015-10-19 06:28:17,916 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 06:28:17,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023 expecting start txid #22
2015-10-19 06:28:17,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023
2015-10-19 06:28:17,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 06:28:17,924 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 21
2015-10-19 06:28:17,924 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000019, cpktTxId=0000000000000000019)
2015-10-19 06:28:17,947 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 23 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-19 06:28:17,947 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 07:28:18,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 07:28:18,406 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=24&endTxId=25&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 07:28:18,412 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 07:28:18,412 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000024-0000000000000000025_0000000000018569257 size 0 bytes.
2015-10-19 07:28:18,413 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 07:28:18,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025 expecting start txid #24
2015-10-19 07:28:18,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025
2015-10-19 07:28:18,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 07:28:18,456 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 23
2015-10-19 07:28:18,457 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000021, cpktTxId=0000000000000000021)
2015-10-19 07:28:18,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 25 to namenode at http://master.hadoop:50070 in 0.024 seconds
2015-10-19 07:28:18,487 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 08:28:18,910 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 08:28:18,910 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=26&endTxId=27&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 08:28:18,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 08:28:18,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000026-0000000000000000027_0000000000022169761 size 0 bytes.
2015-10-19 08:28:18,915 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 08:28:18,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027 expecting start txid #26
2015-10-19 08:28:18,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027
2015-10-19 08:28:18,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 08:28:18,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 25
2015-10-19 08:28:18,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000023, cpktTxId=0000000000000000023)
2015-10-19 08:28:18,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 27 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-19 08:28:18,943 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 09:28:19,363 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 09:28:19,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=28&endTxId=29&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 09:28:19,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 09:28:19,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000028-0000000000000000029_0000000000025770214 size 0 bytes.
2015-10-19 09:28:19,369 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 09:28:19,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029 expecting start txid #28
2015-10-19 09:28:19,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029
2015-10-19 09:28:19,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 09:28:19,377 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 27
2015-10-19 09:28:19,377 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2015-10-19 09:28:19,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 29 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-19 09:28:19,393 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 10:28:19,827 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 10:28:19,827 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=30&endTxId=31&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 10:28:19,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 10:28:19,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000030-0000000000000000031_0000000000029370678 size 0 bytes.
2015-10-19 10:28:19,832 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 10:28:19,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031 expecting start txid #30
2015-10-19 10:28:19,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031
2015-10-19 10:28:19,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 10:28:19,840 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 29
2015-10-19 10:28:19,840 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000027, cpktTxId=0000000000000000027)
2015-10-19 10:28:19,888 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 31 to namenode at http://master.hadoop:50070 in 0.043 seconds
2015-10-19 10:28:19,888 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 11:28:20,345 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 11:28:20,346 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=32&endTxId=33&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 11:28:20,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 11:28:20,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000032-0000000000000000033_0000000000032971196 size 0 bytes.
2015-10-19 11:28:20,351 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 11:28:20,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033 expecting start txid #32
2015-10-19 11:28:20,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033
2015-10-19 11:28:20,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 11:28:20,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 31
2015-10-19 11:28:20,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000029, cpktTxId=0000000000000000029)
2015-10-19 11:28:20,388 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 33 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-19 11:28:20,389 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 12:28:20,842 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 12:28:20,843 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=34&endTxId=35&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 12:28:20,848 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 12:28:20,848 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000034-0000000000000000035_0000000000036571694 size 0 bytes.
2015-10-19 12:28:20,848 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 12:28:20,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035 expecting start txid #34
2015-10-19 12:28:20,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035
2015-10-19 12:28:20,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 12:28:20,856 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 33
2015-10-19 12:28:20,857 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2015-10-19 12:28:20,893 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 35 to namenode at http://master.hadoop:50070 in 0.019 seconds
2015-10-19 12:28:20,893 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 13:28:21,325 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 13:28:21,326 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=36&endTxId=37&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 13:28:21,330 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 13:28:21,330 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000036-0000000000000000037_0000000000040172176 size 0 bytes.
2015-10-19 13:28:21,331 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 13:28:21,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 expecting start txid #36
2015-10-19 13:28:21,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037
2015-10-19 13:28:21,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 13:28:21,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 35
2015-10-19 13:28:21,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000033, cpktTxId=0000000000000000033)
2015-10-19 13:28:21,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 37 to namenode at http://master.hadoop:50070 in 0.049 seconds
2015-10-19 13:28:21,393 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 14:28:21,800 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 14:28:21,801 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=38&endTxId=39&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 14:28:21,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 14:28:21,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000038-0000000000000000039_0000000000043772651 size 0 bytes.
2015-10-19 14:28:21,806 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 14:28:21,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 expecting start txid #38
2015-10-19 14:28:21,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039
2015-10-19 14:28:21,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 14:28:21,814 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 37
2015-10-19 14:28:21,814 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000035, cpktTxId=0000000000000000035)
2015-10-19 14:28:21,837 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 39 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-19 14:28:21,837 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 15:28:22,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 15:28:22,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=40&endTxId=41&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 15:28:22,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-19 15:28:22,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000040-0000000000000000041_0000000000047373085 size 0 bytes.
2015-10-19 15:28:22,247 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 15:28:22,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 expecting start txid #40
2015-10-19 15:28:22,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041
2015-10-19 15:28:22,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 15:28:22,267 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 39
2015-10-19 15:28:22,267 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000037, cpktTxId=0000000000000000037)
2015-10-19 15:28:22,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 41 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-19 15:28:22,290 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 16:28:22,713 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 16:28:22,713 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=42&endTxId=43&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 16:28:22,718 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 16:28:22,718 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000042-0000000000000000043_0000000000050973564 size 0 bytes.
2015-10-19 16:28:22,718 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 16:28:22,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 expecting start txid #42
2015-10-19 16:28:22,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043
2015-10-19 16:28:22,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 16:28:22,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 41
2015-10-19 16:28:22,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000039, cpktTxId=0000000000000000039)
2015-10-19 16:28:22,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 43 to namenode at http://master.hadoop:50070 in 0.026 seconds
2015-10-19 16:28:22,771 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 17:28:23,224 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 17:28:23,224 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=44&endTxId=45&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 17:28:23,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-10-19 17:28:23,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000044-0000000000000000045_0000000000054574075 size 0 bytes.
2015-10-19 17:28:23,246 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 17:28:23,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 expecting start txid #44
2015-10-19 17:28:23,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045
2015-10-19 17:28:23,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 17:28:23,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2015-10-19 17:28:23,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000041, cpktTxId=0000000000000000041)
2015-10-19 17:28:23,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 45 to namenode at http://master.hadoop:50070 in 0.026 seconds
2015-10-19 17:28:23,302 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 18:28:23,784 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-19 18:28:23,785 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=46&endTxId=47&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:28:23,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 18:28:23,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000046-0000000000000000047_0000000000058174635 size 0 bytes.
2015-10-19 18:28:23,790 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 18:28:23,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 expecting start txid #46
2015-10-19 18:28:23,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047
2015-10-19 18:28:23,791 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 18:28:23,821 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 45
2015-10-19 18:28:23,821 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2015-10-19 18:28:23,853 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 47 to namenode at http://master.hadoop:50070 in 0.025 seconds
2015-10-19 18:28:23,853 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 18:34:37,799 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 18:34:37,801 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 18:42:24,324 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 18:42:24,345 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 18:42:26,601 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 18:42:26,783 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 18:42:26,784 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 18:42:27,232 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 10361@master.hadoop
2015-10-19 18:42:27,482 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 18:42:27,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 18:42:27,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 18:42:27,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 18:42:27,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 18:42:27
2015-10-19 18:42:27,566 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 18:42:27,566 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:42:27,567 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 18:42:27,568 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 18:42:27,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 18:42:27,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 18:42:27,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 18:42:27,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 18:42:27,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 18:42:27,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 18:42:27,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 18:42:28,265 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 18:42:28,265 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:42:28,266 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 18:42:28,266 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 18:42:28,267 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 18:42:28,311 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 18:42:28,311 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:42:28,311 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 18:42:28,311 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 18:42:28,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 18:42:28,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 18:42:28,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 18:42:28,323 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 18:42:28,323 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 18:42:28,323 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 18:42:28,353 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 18:42:28,353 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 18:42:28,506 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 18:42:28,515 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 18:42:28,549 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 18:42:28,563 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 18:42:28,564 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 18:42:28,564 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 18:42:28,679 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 18:42:28,679 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 18:42:29,750 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 18:42:29,751 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 18:42:29,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 18:42:29,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 18:43:30,014 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 18:43:30,266 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 18:43:30,824 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=47&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:43:30,957 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 18:43:32,163 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-19 18:43:32,163 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000047 size 627 bytes.
2015-10-19 18:43:32,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=48&endTxId=48&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:43:32,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 37925.93 KB/s
2015-10-19 18:43:32,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000048-0000000000000000048_0000000000059083044 size 0 bytes.
2015-10-19 18:43:32,230 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=49&endTxId=50&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:43:32,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-10-19 18:43:32,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000049-0000000000000000050_0000000000059083080 size 0 bytes.
2015-10-19 18:43:32,292 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 5 INodes.
2015-10-19 18:43:32,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 18:43:32,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 47 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000047
2015-10-19 18:43:32,350 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 18:43:32,377 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-19 18:43:32,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000048 expecting start txid #48
2015-10-19 18:43:32,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000048
2015-10-19 18:43:32,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000048 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-19 18:43:32,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000049-0000000000000000050 expecting start txid #49
2015-10-19 18:43:32,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000049-0000000000000000050
2015-10-19 18:43:32,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000049-0000000000000000050 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 18:43:32,498 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 47
2015-10-19 18:43:32,499 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000045, cpktTxId=0000000000000000045)
2015-10-19 18:43:32,599 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 50 to namenode at http://master.hadoop:50070 in 0.082 seconds
2015-10-19 18:43:32,600 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 18:56:30,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 18:56:30,751 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 18:57:42,393 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 18:57:42,414 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 18:57:44,557 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 18:57:44,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 18:57:44,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 18:57:45,141 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 11748@master.hadoop
2015-10-19 18:57:45,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 18:57:45,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 18:57:45,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 18:57:45,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 18:57:45,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 18:57:45
2015-10-19 18:57:45,452 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 18:57:45,452 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:57:45,454 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 18:57:45,454 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 18:57:45,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 18:57:45,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 18:57:45,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 18:57:45,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 18:57:45,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 18:57:45,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 18:57:45,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 18:57:45,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 18:57:45,903 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 18:57:45,903 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:57:45,904 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 18:57:45,904 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 18:57:45,905 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 18:57:45,939 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 18:57:45,939 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 18:57:45,939 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 18:57:45,939 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 18:57:45,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 18:57:45,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 18:57:45,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 18:57:45,949 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 18:57:45,949 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 18:57:45,949 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 18:57:45,974 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 18:57:45,974 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 18:57:46,113 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 18:57:46,122 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 18:57:46,143 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 18:57:46,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 18:57:46,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 18:57:46,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 18:57:46,187 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 18:57:46,188 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 18:57:47,162 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 18:57:47,163 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 18:57:47,179 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 18:57:47,179 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 18:58:47,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 18:58:47,644 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 18:58:48,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=50&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:58:48,311 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 18:58:49,449 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-10-19 18:58:49,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000050 size 627 bytes.
2015-10-19 18:58:49,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=51&endTxId=51&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:58:49,498 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 40960.00 KB/s
2015-10-19 18:58:49,498 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000051-0000000000000000051_0000000000060000320 size 0 bytes.
2015-10-19 18:58:49,499 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=52&endTxId=53&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 18:58:49,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 18:58:49,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000052-0000000000000000053_0000000000060000350 size 0 bytes.
2015-10-19 18:58:49,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 5 INodes.
2015-10-19 18:58:49,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 18:58:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 50 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000050
2015-10-19 18:58:49,603 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 18:58:49,618 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-19 18:58:49,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051 expecting start txid #51
2015-10-19 18:58:49,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051
2015-10-19 18:58:49,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-19 18:58:49,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 expecting start txid #52
2015-10-19 18:58:49,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053
2015-10-19 18:58:49,682 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 18:58:49,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 50
2015-10-19 18:58:49,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000047, cpktTxId=0000000000000000047)
2015-10-19 18:58:49,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 53 to namenode at http://master.hadoop:50070 in 0.072 seconds
2015-10-19 18:58:49,857 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 19:08:21,422 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 19:08:21,423 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 19:09:03,761 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 19:09:03,781 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 19:09:05,934 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 19:09:06,113 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 19:09:06,113 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 19:09:06,541 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 13284@master.hadoop
2015-10-19 19:09:06,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 19:09:06,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 19:09:06,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 19:09:06,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 19:09:06,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 19:09:06
2015-10-19 19:09:06,850 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 19:09:06,850 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:09:06,852 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 19:09:06,852 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 19:09:06,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 19:09:06,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 19:09:06,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 19:09:06,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 19:09:06,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 19:09:06,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 19:09:06,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 19:09:06,911 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 19:09:07,616 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 19:09:07,616 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:09:07,616 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 19:09:07,616 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 19:09:07,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 19:09:07,650 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 19:09:07,650 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:09:07,650 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 19:09:07,650 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 19:09:07,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 19:09:07,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 19:09:07,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 19:09:07,662 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 19:09:07,662 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 19:09:07,662 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 19:09:07,687 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 19:09:07,687 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 19:09:07,840 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 19:09:07,844 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 19:09:07,868 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 19:09:07,877 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 19:09:07,877 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 19:09:07,877 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 19:09:07,912 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 19:09:07,912 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 19:09:08,933 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 19:09:08,933 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 19:09:08,950 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 19:09:08,950 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 19:10:09,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 19:10:09,533 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 19:10:10,070 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=53&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 19:10:10,205 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 19:10:11,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-10-19 19:10:11,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000053 size 627 bytes.
2015-10-19 19:10:11,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=54&endTxId=54&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 19:10:11,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 36571.43 KB/s
2015-10-19 19:10:11,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000054-0000000000000000054_0000000000060682213 size 0 bytes.
2015-10-19 19:10:11,398 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=55&endTxId=56&storageInfo=-57:993055729:0:CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d
2015-10-19 19:10:11,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-10-19 19:10:11,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000055-0000000000000000056_0000000000060682249 size 0 bytes.
2015-10-19 19:10:11,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 5 INodes.
2015-10-19 19:10:11,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 19:10:11,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 53 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000053
2015-10-19 19:10:11,527 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 19:10:11,542 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-19 19:10:11,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000054 expecting start txid #54
2015-10-19 19:10:11,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000054
2015-10-19 19:10:11,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000054 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-19 19:10:11,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000056 expecting start txid #55
2015-10-19 19:10:11,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000056
2015-10-19 19:10:11,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000056 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 19:10:11,664 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 53
2015-10-19 19:10:11,664 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000050, cpktTxId=0000000000000000050)
2015-10-19 19:10:11,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 56 to namenode at http://master.hadoop:50070 in 0.088 seconds
2015-10-19 19:10:11,774 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 627
2015-10-19 19:32:57,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 19:32:57,791 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 19:36:54,076 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 19:36:54,096 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 19:36:56,251 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 19:36:56,432 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 19:36:56,432 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 19:36:56,849 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 14840@master.hadoop
2015-10-19 19:36:57,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 19:36:57,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 19:36:57,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 19:36:57,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 19:36:57,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 19:36:57
2015-10-19 19:36:57,157 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 19:36:57,157 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:36:57,158 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 19:36:57,158 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 19:36:57,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 19:36:57,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 19:36:57,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 19:36:57,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 19:36:57,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 19:36:57,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 19:36:57,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 19:36:57,654 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 19:36:57,654 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:36:57,654 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 19:36:57,654 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 19:36:57,655 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 19:36:57,699 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 19:36:57,699 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:36:57,700 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 19:36:57,700 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 19:36:57,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 19:36:57,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 19:36:57,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 19:36:57,704 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 19:36:57,704 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 19:36:57,704 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 19:36:57,731 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 19:36:57,731 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 19:36:57,870 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 19:36:57,881 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 19:36:57,904 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 19:36:57,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 19:36:57,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 19:36:57,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 19:36:57,954 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 19:36:57,954 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 19:36:58,946 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 19:36:58,947 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 19:36:58,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 19:36:58,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 19:38:00,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:01,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:02,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:03,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:04,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:05,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:06,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:07,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:08,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 19:38:08,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 19:38:08,642 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 19:39:25,279 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 19:39:25,298 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 19:39:27,465 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 19:39:27,645 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 19:39:27,645 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 19:39:28,081 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 16003@master.hadoop
2015-10-19 19:39:28,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 19:39:28,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 19:39:28,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 19:39:28,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 19:39:28,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 19:39:28
2015-10-19 19:39:28,391 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 19:39:28,391 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:39:28,393 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 19:39:28,393 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 19:39:28,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 19:39:28,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 19:39:28,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 19:39:28,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 19:39:28,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 19:39:28,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 19:39:28,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 19:39:28,915 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 19:39:28,916 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:39:28,916 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 19:39:28,916 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 19:39:28,917 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 19:39:28,953 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 19:39:28,953 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:39:28,953 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 19:39:28,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 19:39:28,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 19:39:28,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 19:39:28,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 19:39:28,960 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 19:39:28,961 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 19:39:28,961 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 19:39:28,989 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 19:39:28,990 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 19:39:29,131 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 19:39:29,142 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 19:39:29,162 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 19:39:29,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 19:39:29,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 19:39:29,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 19:39:29,208 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 19:39:29,208 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 19:39:30,249 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 19:39:30,249 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 19:39:30,265 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 19:39:30,265 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 19:40:30,440 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:41:30,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:42:30,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:43:26,059 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 19:43:26,061 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 19:51:02,514 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 19:51:02,533 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 19:51:04,684 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 19:51:04,861 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 19:51:04,861 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 19:51:05,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 17276@master.hadoop
2015-10-19 19:51:05,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 19:51:05,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 19:51:05,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 19:51:05,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 19:51:05,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 19:51:05
2015-10-19 19:51:05,572 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 19:51:05,572 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:51:05,574 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 19:51:05,574 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 19:51:05,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 19:51:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 19:51:05,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 19:51:05,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 19:51:05,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 19:51:05,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 19:51:05,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 19:51:06,030 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 19:51:06,030 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:51:06,030 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 19:51:06,030 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 19:51:06,031 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 19:51:06,064 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 19:51:06,064 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 19:51:06,069 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 19:51:06,069 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 19:51:06,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 19:51:06,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 19:51:06,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 19:51:06,074 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 19:51:06,074 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 19:51:06,075 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 19:51:06,103 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 19:51:06,104 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 19:51:06,236 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 19:51:06,241 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 19:51:06,268 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 19:51:06,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 19:51:06,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 19:51:06,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 19:51:06,312 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 19:51:06,312 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 19:51:07,297 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 19:51:07,298 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 19:51:07,314 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 19:51:07,314 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 19:52:07,617 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:53:07,652 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:54:07,691 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:55:07,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:56:07,778 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:57:07,842 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:58:07,918 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 19:59:07,977 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:00:08,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:01:08,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:02:08,115 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:03:08,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:04:08,206 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:04:54,246 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 20:04:54,248 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 20:06:34,237 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 20:06:34,257 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 20:06:36,498 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 20:06:36,675 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 20:06:36,675 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 20:06:37,110 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 18576@master.hadoop
2015-10-19 20:06:37,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 20:06:37,426 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 20:06:37,426 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 20:06:37,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 20:06:37,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 20:06:37
2015-10-19 20:06:37,431 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 20:06:37,431 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 20:06:37,433 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 20:06:37,433 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 20:06:37,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 20:06:37,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 20:06:37,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 20:06:37,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 20:06:37,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 20:06:37,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 20:06:37,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 20:06:38,040 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 20:06:38,040 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 20:06:38,040 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 20:06:38,040 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 20:06:38,046 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 20:06:38,082 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 20:06:38,082 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 20:06:38,082 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 20:06:38,082 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 20:06:38,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 20:06:38,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 20:06:38,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 20:06:38,086 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 20:06:38,086 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 20:06:38,087 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 20:06:38,118 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 20:06:38,118 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 20:06:38,268 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 20:06:38,272 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 20:06:38,311 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 20:06:38,326 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 20:06:38,326 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 20:06:38,326 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 20:06:38,432 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 20:06:38,433 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 20:06:39,479 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 20:06:39,479 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 20:06:39,496 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 20:06:39,496 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 20:07:39,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:08:39,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:09:39,779 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:10:39,824 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:11:39,869 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:12:39,908 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:13:39,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:14:40,004 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:15:40,106 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:16:40,202 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:17:40,250 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:18:40,295 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:19:40,314 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:20:40,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:21:40,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:22:40,403 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:23:40,452 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:24:40,503 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:25:40,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:26:40,609 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:27:40,665 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:28:40,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:29:40,796 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:30:40,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:31:40,892 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:32:40,943 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:33:40,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:34:41,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:35:41,100 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:36:41,144 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:37:41,192 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:38:41,240 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:39:41,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:40:41,348 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:41:41,426 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:42:41,476 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:43:41,523 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:44:41,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:45:41,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:46:41,672 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:47:41,720 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:48:41,768 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:49:41,816 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:50:41,864 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:51:41,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:52:41,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:53:42,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:54:42,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:55:42,116 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:56:42,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:57:42,220 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:58:42,268 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 20:59:42,320 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:00:42,368 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:01:42,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:02:42,464 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:03:42,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:04:42,564 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:05:42,612 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:06:42,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:07:42,712 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:08:42,760 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:09:42,808 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:10:42,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:11:42,905 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:12:42,956 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:13:43,004 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:14:43,052 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:15:43,100 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:16:43,148 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:17:43,196 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:18:43,244 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:19:43,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:20:43,340 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:21:43,423 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:22:43,472 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:23:43,520 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:24:43,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:25:43,617 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:26:43,664 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:27:43,712 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:28:43,761 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:29:43,808 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:30:43,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:31:43,905 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:32:43,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:33:43,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:34:44,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:35:44,093 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:36:44,144 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:37:44,223 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:38:44,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:39:44,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:40:44,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:41:44,413 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:42:44,461 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:43:44,509 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:44:44,556 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:45:44,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:46:44,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:47:44,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:48:44,781 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:49:44,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:50:44,893 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:51:44,945 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:52:45,001 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:53:45,079 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:54:45,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:55:45,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:56:45,181 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:57:45,201 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:58:45,222 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 21:59:45,254 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:00:45,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:01:45,287 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:02:45,304 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:03:45,320 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:04:45,342 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:05:45,358 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:06:45,375 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:07:45,421 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:08:45,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:09:45,551 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:10:45,597 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:11:45,646 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:12:45,693 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:13:45,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:14:45,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:15:45,841 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:16:45,889 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:17:45,933 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:18:45,981 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:19:46,033 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:20:46,081 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:21:46,125 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:22:46,173 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:23:46,221 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:24:46,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:25:46,325 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:26:46,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:27:46,425 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:28:35,721 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 22:28:35,722 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 22:29:31,826 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 22:29:31,846 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 22:29:34,114 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 22:29:34,293 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 22:29:34,293 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 22:29:34,692 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 20427@master.hadoop
2015-10-19 22:29:34,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 22:29:35,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 22:29:35,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 22:29:35,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 22:29:35,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 22:29:35
2015-10-19 22:29:35,039 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 22:29:35,039 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:29:35,043 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 22:29:35,043 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 22:29:35,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 22:29:35,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 22:29:35,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 22:29:35,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 22:29:35,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 22:29:35,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 22:29:35,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 22:29:35,722 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 22:29:35,722 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:29:35,723 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 22:29:35,723 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 22:29:35,724 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 22:29:35,770 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 22:29:35,770 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:29:35,770 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 22:29:35,770 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 22:29:35,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 22:29:35,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 22:29:35,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 22:29:35,783 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 22:29:35,783 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 22:29:35,783 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 22:29:35,814 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 22:29:35,814 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 22:29:35,959 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 22:29:35,968 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 22:29:36,018 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 22:29:36,020 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 22:29:36,021 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 22:29:36,021 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 22:29:36,145 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 22:29:36,145 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 22:29:37,151 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 22:29:37,151 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 22:29:37,167 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 22:29:37,167 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 22:30:37,475 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:31:37,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:32:37,561 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:33:37,609 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:34:37,657 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:35:37,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:36:37,746 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:37:37,794 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:38:37,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:39:37,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:40:37,946 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:41:37,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:42:38,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:43:38,090 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:44:38,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:45:38,178 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:46:38,229 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:47:38,286 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:48:38,333 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:49:38,353 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -57 namespaceID = 1106571674 cTime = 0 ; clusterId = CID-f0b59983-d498-4573-87a0-e3ef425f3868 ; blockpoolId = BP-1680780112-127.0.0.1-1445308734642.
Expecting respectively: -57; 993055729; 0; CID-4ed4c3d6-bc0a-4598-baab-6b1c6fb9f62d; BP-882371229-127.0.0.1-1445243950608.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2015-10-19 22:50:26,015 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 22:50:26,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 22:51:35,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 22:51:35,472 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 22:51:37,634 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 22:51:37,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 22:51:37,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 22:51:38,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 21781@master.hadoop
2015-10-19 22:51:38,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 22:51:38,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 22:51:38,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 22:51:38,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 22:51:38,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 22:51:38
2015-10-19 22:51:38,441 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 22:51:38,441 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:51:38,443 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 22:51:38,443 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 22:51:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 22:51:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 22:51:38,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 22:51:38,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 22:51:38,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 22:51:38,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 22:51:38,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 22:51:38,503 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 22:51:38,851 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 22:51:38,851 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:51:38,851 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 22:51:38,851 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 22:51:38,852 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 22:51:38,868 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 22:51:38,868 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 22:51:38,868 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 22:51:38,868 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 22:51:38,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 22:51:38,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 22:51:38,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 22:51:38,872 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 22:51:38,872 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 22:51:38,872 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 22:51:38,896 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 22:51:38,896 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 22:51:39,040 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 22:51:39,052 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 22:51:39,078 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 22:51:39,080 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 22:51:39,080 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 22:51:39,081 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 22:51:39,124 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 22:51:39,124 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 22:51:40,139 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 22:51:40,139 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 22:51:40,155 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 22:51:40,155 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 22:52:41,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:42,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:43,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:44,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:45,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:46,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:47,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:48,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:49,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:50,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:52:50,210 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:53:51,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:52,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:53,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:54,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:55,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:56,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:57,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:58,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:53:59,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:54:00,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:54:00,222 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:55:01,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:02,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:03,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:04,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:05,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:06,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:07,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:08,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:09,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:10,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:55:10,240 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:56:11,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:12,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:13,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:14,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:15,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:16,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:17,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:18,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:19,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:20,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:56:20,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:57:21,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:22,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:23,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:24,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:25,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:26,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:27,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:28,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:29,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:30,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:57:30,262 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:58:31,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:32,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:33,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:34,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:35,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:36,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:37,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:38,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:39,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:40,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:58:40,273 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 22:59:41,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:42,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:43,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:44,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:45,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:46,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:47,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:48,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:49,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:50,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-19 22:59:50,285 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From master.hadoop/127.0.0.1 to master.hadoop:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 18 more
2015-10-19 23:00:09,747 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-19 23:00:09,749 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-19 23:02:30,273 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-19 23:02:30,293 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-19 23:02:32,458 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-19 23:02:32,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-19 23:02:32,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-19 23:02:33,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 22967@master.hadoop
2015-10-19 23:02:33,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-19 23:02:33,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-19 23:02:33,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-19 23:02:33,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-19 23:02:33,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 19 23:02:33
2015-10-19 23:02:33,096 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-19 23:02:33,096 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 23:02:33,098 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-19 23:02:33,098 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-19 23:02:33,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-19 23:02:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-19 23:02:33,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-19 23:02:33,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-19 23:02:33,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-19 23:02:33,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-19 23:02:33,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-19 23:02:33,511 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-19 23:02:33,511 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 23:02:33,511 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-19 23:02:33,511 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-19 23:02:33,512 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-19 23:02:33,527 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-19 23:02:33,527 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-19 23:02:33,527 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-19 23:02:33,527 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-19 23:02:33,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-19 23:02:33,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-19 23:02:33,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-19 23:02:33,531 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-19 23:02:33,531 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-19 23:02:33,531 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-19 23:02:33,545 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-19 23:02:33,545 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-19 23:02:33,612 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-19 23:02:33,617 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-19 23:02:33,628 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-19 23:02:33,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-19 23:02:33,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-19 23:02:33,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-19 23:02:33,650 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-19 23:02:33,650 INFO org.mortbay.log: jetty-6.1.26
2015-10-19 23:02:34,770 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-19 23:02:34,771 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-19 23:02:34,787 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-19 23:02:34,787 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-19 23:03:35,131 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-19 23:03:35,401 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-19 23:03:35,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=0&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-19 23:03:36,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-19 23:03:37,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-10-19 23:03:37,036 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 355 bytes.
2015-10-19 23:03:37,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-19 23:03:37,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-19 23:03:37,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000074687893 size 0 bytes.
2015-10-19 23:03:37,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-19 23:03:37,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-19 23:03:37,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000000
2015-10-19 23:03:37,126 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-19 23:03:37,133 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-19 23:03:37,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2015-10-19 23:03:37,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2015-10-19 23:03:37,161 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2015-10-19 23:03:37,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary
2015-10-19 23:03:37,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://master.hadoop:50070 in 0.031 seconds
2015-10-19 23:03:37,305 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 00:03:37,745 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 00:03:37,746 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 00:03:37,757 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 00:03:37,757 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000078288596 size 0 bytes.
2015-10-20 00:03:37,757 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 00:03:37,758 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2015-10-20 00:03:37,758 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004
2015-10-20 00:03:37,758 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 00:03:37,784 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2015-10-20 00:03:37,784 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2015-10-20 00:03:37,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4 to namenode at http://master.hadoop:50070 in 0.02 seconds
2015-10-20 00:03:37,811 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 00:29:14,591 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-20 00:29:14,593 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-20 00:30:46,781 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-20 00:30:46,801 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-20 00:30:48,951 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-20 00:30:49,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-20 00:30:49,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-20 00:30:49,599 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 24534@master.hadoop
2015-10-20 00:30:49,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-20 00:30:49,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-20 00:30:49,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-20 00:30:49,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-20 00:30:49,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 20 00:30:49
2015-10-20 00:30:49,906 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-20 00:30:49,906 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-20 00:30:49,908 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-20 00:30:49,908 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-20 00:30:49,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-20 00:30:49,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-20 00:30:49,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-20 00:30:49,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-20 00:30:49,962 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-20 00:30:49,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-20 00:30:49,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-20 00:30:50,430 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-20 00:30:50,430 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-20 00:30:50,431 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-20 00:30:50,431 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-20 00:30:50,432 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-20 00:30:50,465 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-20 00:30:50,465 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-20 00:30:50,465 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-20 00:30:50,465 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-20 00:30:50,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-20 00:30:50,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-20 00:30:50,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-20 00:30:50,477 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-20 00:30:50,477 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-20 00:30:50,477 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-20 00:30:50,500 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-20 00:30:50,500 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-20 00:30:50,639 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-20 00:30:50,649 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-20 00:30:50,672 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-20 00:30:50,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-20 00:30:50,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-20 00:30:50,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-20 00:30:50,718 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-20 00:30:50,718 INFO org.mortbay.log: jetty-6.1.26
2015-10-20 00:30:51,702 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-20 00:30:51,702 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-20 00:30:51,718 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-20 00:30:51,718 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-20 00:31:52,045 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-20 00:31:52,296 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-20 00:31:52,850 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=4&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 00:31:52,978 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-20 00:31:54,020 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 00:31:54,020 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 355 bytes.
2015-10-20 00:31:54,027 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=5&endTxId=5&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 00:31:54,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 102400.00 KB/s
2015-10-20 00:31:54,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000005-0000000000000000005_0000000000079984877 size 0 bytes.
2015-10-20 00:31:54,042 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=6&endTxId=7&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 00:31:54,075 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-20 00:31:54,075 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000006-0000000000000000007_0000000000079984892 size 0 bytes.
2015-10-20 00:31:54,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-20 00:31:54,166 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-20 00:31:54,167 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000004
2015-10-20 00:31:54,167 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-20 00:31:54,197 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-20 00:31:54,206 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000005 expecting start txid #5
2015-10-20 00:31:54,206 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000005
2015-10-20 00:31:54,254 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000005 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-20 00:31:54,254 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000006-0000000000000000007 expecting start txid #6
2015-10-20 00:31:54,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000006-0000000000000000007
2015-10-20 00:31:54,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000006-0000000000000000007 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 00:31:54,338 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2015-10-20 00:31:54,338 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2015-10-20 00:31:54,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 7 to namenode at http://master.hadoop:50070 in 0.033 seconds
2015-10-20 00:31:54,381 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 01:31:54,813 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 01:31:54,813 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=8&endTxId=9&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 01:31:54,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 01:31:54,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000008-0000000000000000009_0000000000083585664 size 0 bytes.
2015-10-20 01:31:54,826 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 01:31:54,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009 expecting start txid #8
2015-10-20 01:31:54,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009
2015-10-20 01:31:54,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000009 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 01:31:54,854 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 7
2015-10-20 01:31:54,857 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2015-10-20 01:31:54,880 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 9 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-20 01:31:54,880 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 02:31:55,304 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 02:31:55,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=10&endTxId=11&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 02:31:55,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 02:31:55,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000010-0000000000000000011_0000000000087186155 size 0 bytes.
2015-10-20 02:31:55,310 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 02:31:55,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000010-0000000000000000011 expecting start txid #10
2015-10-20 02:31:55,311 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000010-0000000000000000011
2015-10-20 02:31:55,311 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000010-0000000000000000011 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 02:31:55,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 9
2015-10-20 02:31:55,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000007, cpktTxId=0000000000000000007)
2015-10-20 02:31:55,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 11 to namenode at http://master.hadoop:50070 in 0.042 seconds
2015-10-20 02:31:55,365 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 03:31:55,784 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 03:31:55,784 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=12&endTxId=13&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 03:31:55,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 03:31:55,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000012-0000000000000000013_0000000000090786635 size 0 bytes.
2015-10-20 03:31:55,789 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 03:31:55,789 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000012-0000000000000000013 expecting start txid #12
2015-10-20 03:31:55,789 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000012-0000000000000000013
2015-10-20 03:31:55,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000012-0000000000000000013 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 03:31:55,796 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 11
2015-10-20 03:31:55,797 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000009, cpktTxId=0000000000000000009)
2015-10-20 03:31:55,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 13 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-20 03:31:55,822 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 04:31:56,244 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 04:31:56,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=14&endTxId=15&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 04:31:56,249 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 04:31:56,249 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000014-0000000000000000015_0000000000094387095 size 0 bytes.
2015-10-20 04:31:56,249 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 04:31:56,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000014-0000000000000000015 expecting start txid #14
2015-10-20 04:31:56,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000014-0000000000000000015
2015-10-20 04:31:56,250 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000014-0000000000000000015 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 04:31:56,257 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 13
2015-10-20 04:31:56,257 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2015-10-20 04:31:56,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 15 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-20 04:31:56,274 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 05:31:56,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 05:31:56,702 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=16&endTxId=17&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 05:31:56,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 05:31:56,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000016-0000000000000000017_0000000000097987552 size 0 bytes.
2015-10-20 05:31:56,707 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 05:31:56,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017 expecting start txid #16
2015-10-20 05:31:56,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017
2015-10-20 05:31:56,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000016-0000000000000000017 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 05:31:56,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 15
2015-10-20 05:31:56,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000013, cpktTxId=0000000000000000013)
2015-10-20 05:31:56,765 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 17 to namenode at http://master.hadoop:50070 in 0.04 seconds
2015-10-20 05:31:56,765 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 06:31:57,177 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 06:31:57,178 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=18&endTxId=19&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 06:31:57,182 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 06:31:57,182 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000018-0000000000000000019_0000000000101588028 size 0 bytes.
2015-10-20 06:31:57,183 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 06:31:57,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019 expecting start txid #18
2015-10-20 06:31:57,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019
2015-10-20 06:31:57,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000018-0000000000000000019 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 06:31:57,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 17
2015-10-20 06:31:57,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000015, cpktTxId=0000000000000000015)
2015-10-20 06:31:57,208 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 19 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-20 06:31:57,208 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 07:31:57,616 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 07:31:57,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=20&endTxId=21&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 07:31:57,620 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 07:31:57,620 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000020-0000000000000000021_0000000000105188467 size 0 bytes.
2015-10-20 07:31:57,621 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 07:31:57,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021 expecting start txid #20
2015-10-20 07:31:57,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021
2015-10-20 07:31:57,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000020-0000000000000000021 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 07:31:57,628 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 19
2015-10-20 07:31:57,628 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000017, cpktTxId=0000000000000000017)
2015-10-20 07:31:57,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 21 to namenode at http://master.hadoop:50070 in 0.009 seconds
2015-10-20 07:31:57,642 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 08:31:58,054 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 08:31:58,055 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=22&endTxId=23&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 08:31:58,066 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 08:31:58,066 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000022-0000000000000000023_0000000000108788905 size 0 bytes.
2015-10-20 08:31:58,067 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 08:31:58,067 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023 expecting start txid #22
2015-10-20 08:31:58,067 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023
2015-10-20 08:31:58,068 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000022-0000000000000000023 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 08:31:58,074 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 21
2015-10-20 08:31:58,074 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000019, cpktTxId=0000000000000000019)
2015-10-20 08:31:58,133 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 23 to namenode at http://master.hadoop:50070 in 0.047 seconds
2015-10-20 08:31:58,133 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 09:31:58,542 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 09:31:58,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=24&endTxId=25&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 09:31:58,551 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 09:31:58,551 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000024-0000000000000000025_0000000000112389393 size 0 bytes.
2015-10-20 09:31:58,552 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 09:31:58,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025 expecting start txid #24
2015-10-20 09:31:58,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025
2015-10-20 09:31:58,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000024-0000000000000000025 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 09:31:58,563 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 23
2015-10-20 09:31:58,563 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000021, cpktTxId=0000000000000000021)
2015-10-20 09:31:58,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 25 to namenode at http://master.hadoop:50070 in 0.02 seconds
2015-10-20 09:31:58,595 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 10:31:59,020 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 10:31:59,020 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=26&endTxId=27&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 10:31:59,024 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 10:31:59,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000026-0000000000000000027_0000000000115989871 size 0 bytes.
2015-10-20 10:31:59,025 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 10:31:59,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027 expecting start txid #26
2015-10-20 10:31:59,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027
2015-10-20 10:31:59,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000026-0000000000000000027 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 10:31:59,033 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 25
2015-10-20 10:31:59,033 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000023, cpktTxId=0000000000000000023)
2015-10-20 10:31:59,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 27 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-20 10:31:59,048 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 11:31:59,471 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 11:31:59,471 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=28&endTxId=29&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 11:31:59,475 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 11:31:59,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000028-0000000000000000029_0000000000119590322 size 0 bytes.
2015-10-20 11:31:59,476 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 11:31:59,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029 expecting start txid #28
2015-10-20 11:31:59,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029
2015-10-20 11:31:59,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000028-0000000000000000029 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 11:31:59,515 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 27
2015-10-20 11:31:59,516 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2015-10-20 11:31:59,537 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 29 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-20 11:31:59,537 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 12:31:59,952 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 12:31:59,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=30&endTxId=31&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 12:31:59,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 12:31:59,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000030-0000000000000000031_0000000000123190803 size 0 bytes.
2015-10-20 12:31:59,963 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 12:31:59,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031 expecting start txid #30
2015-10-20 12:31:59,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031
2015-10-20 12:31:59,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000030-0000000000000000031 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 12:31:59,978 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 29
2015-10-20 12:31:59,978 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000027, cpktTxId=0000000000000000027)
2015-10-20 12:32:00,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 31 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-20 12:32:00,015 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 13:32:00,424 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 13:32:00,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=32&endTxId=33&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 13:32:00,435 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 13:32:00,435 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000032-0000000000000000033_0000000000126791275 size 0 bytes.
2015-10-20 13:32:00,435 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 13:32:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033 expecting start txid #32
2015-10-20 13:32:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033
2015-10-20 13:32:00,436 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000032-0000000000000000033 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 13:32:00,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 31
2015-10-20 13:32:00,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000029, cpktTxId=0000000000000000029)
2015-10-20 13:32:00,462 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 33 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-20 13:32:00,462 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 14:32:00,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 14:32:00,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=34&endTxId=35&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 14:32:00,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-20 14:32:00,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000034-0000000000000000035_0000000000130391735 size 0 bytes.
2015-10-20 14:32:00,919 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 14:32:00,919 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035 expecting start txid #34
2015-10-20 14:32:00,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035
2015-10-20 14:32:00,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000034-0000000000000000035 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 14:32:00,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 33
2015-10-20 14:32:00,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2015-10-20 14:32:00,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 35 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-20 14:32:00,954 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 15:32:01,370 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 15:32:01,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=36&endTxId=37&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 15:32:01,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-20 15:32:01,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000036-0000000000000000037_0000000000133992221 size 0 bytes.
2015-10-20 15:32:01,381 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 15:32:01,381 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 expecting start txid #36
2015-10-20 15:32:01,381 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037
2015-10-20 15:32:01,382 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 15:32:01,390 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 35
2015-10-20 15:32:01,390 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000033, cpktTxId=0000000000000000033)
2015-10-20 15:32:01,409 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 37 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-20 15:32:01,409 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 16:32:01,812 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 16:32:01,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=38&endTxId=39&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 16:32:01,816 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 16:32:01,817 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000038-0000000000000000039_0000000000137592663 size 0 bytes.
2015-10-20 16:32:01,817 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 16:32:01,817 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 expecting start txid #38
2015-10-20 16:32:01,817 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039
2015-10-20 16:32:01,818 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 16:32:01,825 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 37
2015-10-20 16:32:01,825 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000035, cpktTxId=0000000000000000035)
2015-10-20 16:32:01,841 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 39 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-20 16:32:01,841 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 17:32:02,259 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 17:32:02,259 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=40&endTxId=41&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 17:32:02,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-20 17:32:02,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000040-0000000000000000041_0000000000141193110 size 0 bytes.
2015-10-20 17:32:02,294 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 17:32:02,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 expecting start txid #40
2015-10-20 17:32:02,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041
2015-10-20 17:32:02,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 17:32:02,302 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 39
2015-10-20 17:32:02,302 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000037, cpktTxId=0000000000000000037)
2015-10-20 17:32:02,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 41 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-20 17:32:02,320 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 18:32:02,737 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 18:32:02,738 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=42&endTxId=43&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 18:32:02,742 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 18:32:02,742 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000042-0000000000000000043_0000000000144793588 size 0 bytes.
2015-10-20 18:32:02,743 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 18:32:02,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 expecting start txid #42
2015-10-20 18:32:02,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043
2015-10-20 18:32:02,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 18:32:02,750 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 41
2015-10-20 18:32:02,750 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000039, cpktTxId=0000000000000000039)
2015-10-20 18:32:02,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 43 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-20 18:32:02,767 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 19:32:03,188 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 19:32:03,189 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=44&endTxId=45&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 19:32:03,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 19:32:03,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000044-0000000000000000045_0000000000148394039 size 0 bytes.
2015-10-20 19:32:03,193 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 19:32:03,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 expecting start txid #44
2015-10-20 19:32:03,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045
2015-10-20 19:32:03,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 19:32:03,201 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2015-10-20 19:32:03,201 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000041, cpktTxId=0000000000000000041)
2015-10-20 19:32:03,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 45 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-20 19:32:03,220 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 20:32:03,681 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 20:32:03,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=46&endTxId=47&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 20:32:03,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 20:32:03,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000046-0000000000000000047_0000000000151994533 size 0 bytes.
2015-10-20 20:32:03,687 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 20:32:03,687 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 expecting start txid #46
2015-10-20 20:32:03,687 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047
2015-10-20 20:32:03,688 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 20:32:03,695 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 45
2015-10-20 20:32:03,695 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2015-10-20 20:32:03,713 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 47 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-20 20:32:03,713 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 21:32:04,139 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 21:32:04,139 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=48&endTxId=49&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 21:32:04,145 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 21:32:04,145 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000048-0000000000000000049_0000000000155594990 size 0 bytes.
2015-10-20 21:32:04,146 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 21:32:04,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049 expecting start txid #48
2015-10-20 21:32:04,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049
2015-10-20 21:32:04,147 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 21:32:04,156 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 47
2015-10-20 21:32:04,156 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000045, cpktTxId=0000000000000000045)
2015-10-20 21:32:04,182 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 49 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-20 21:32:04,182 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 22:32:04,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 22:32:04,590 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=50&endTxId=51&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 22:32:04,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 22:32:04,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000050-0000000000000000051_0000000000159195441 size 0 bytes.
2015-10-20 22:32:04,595 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 22:32:04,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000051 expecting start txid #50
2015-10-20 22:32:04,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000051
2015-10-20 22:32:04,596 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000051 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 22:32:04,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 49
2015-10-20 22:32:04,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000047, cpktTxId=0000000000000000047)
2015-10-20 22:32:04,627 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 51 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-20 22:32:04,627 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-20 23:32:05,028 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-20 23:32:05,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=52&endTxId=53&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-20 23:32:05,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-20 23:32:05,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000052-0000000000000000053_0000000000162795879 size 0 bytes.
2015-10-20 23:32:05,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-20 23:32:05,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 expecting start txid #52
2015-10-20 23:32:05,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053
2015-10-20 23:32:05,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 of size 42 edits # 2 loaded in 0 seconds
2015-10-20 23:32:05,041 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 51
2015-10-20 23:32:05,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000049, cpktTxId=0000000000000000049)
2015-10-20 23:32:05,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 53 to namenode at http://master.hadoop:50070 in 0.019 seconds
2015-10-20 23:32:05,067 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 00:32:05,479 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 00:32:05,480 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=54&endTxId=55&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 00:32:05,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 00:32:05,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000054-0000000000000000055_0000000000166396330 size 0 bytes.
2015-10-21 00:32:05,485 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 00:32:05,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055 expecting start txid #54
2015-10-21 00:32:05,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055
2015-10-21 00:32:05,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 00:32:05,493 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 53
2015-10-21 00:32:05,493 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000051, cpktTxId=0000000000000000051)
2015-10-21 00:32:05,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 55 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 00:32:05,514 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 01:32:05,953 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 01:32:05,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=56&endTxId=57&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 01:32:05,957 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 01:32:05,958 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000056-0000000000000000057_0000000000169996804 size 0 bytes.
2015-10-21 01:32:05,958 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 01:32:05,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057 expecting start txid #56
2015-10-21 01:32:05,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057
2015-10-21 01:32:05,959 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 01:32:05,965 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 55
2015-10-21 01:32:05,966 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000053, cpktTxId=0000000000000000053)
2015-10-21 01:32:06,032 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 57 to namenode at http://master.hadoop:50070 in 0.059 seconds
2015-10-21 01:32:06,032 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 02:32:06,450 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 02:32:06,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=58&endTxId=59&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 02:32:06,455 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 02:32:06,455 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000058-0000000000000000059_0000000000173597301 size 0 bytes.
2015-10-21 02:32:06,455 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 02:32:06,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059 expecting start txid #58
2015-10-21 02:32:06,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059
2015-10-21 02:32:06,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 02:32:06,462 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 57
2015-10-21 02:32:06,462 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000055, cpktTxId=0000000000000000055)
2015-10-21 02:32:06,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 59 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 02:32:06,483 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 03:32:06,907 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 03:32:06,907 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=60&endTxId=61&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 03:32:06,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-21 03:32:06,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000060-0000000000000000061_0000000000177197758 size 0 bytes.
2015-10-21 03:32:06,916 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 03:32:06,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061 expecting start txid #60
2015-10-21 03:32:06,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061
2015-10-21 03:32:06,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 03:32:06,927 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 59
2015-10-21 03:32:06,927 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000057, cpktTxId=0000000000000000057)
2015-10-21 03:32:06,956 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 61 to namenode at http://master.hadoop:50070 in 0.021 seconds
2015-10-21 03:32:06,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 04:32:07,360 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 04:32:07,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=62&endTxId=63&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 04:32:07,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 04:32:07,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000062-0000000000000000063_0000000000180798211 size 0 bytes.
2015-10-21 04:32:07,365 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 04:32:07,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063 expecting start txid #62
2015-10-21 04:32:07,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063
2015-10-21 04:32:07,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 04:32:07,372 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 61
2015-10-21 04:32:07,372 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000059, cpktTxId=0000000000000000059)
2015-10-21 04:32:07,438 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 63 to namenode at http://master.hadoop:50070 in 0.059 seconds
2015-10-21 04:32:07,438 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 05:32:07,847 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 05:32:07,847 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=64&endTxId=65&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 05:32:07,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 05:32:07,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000064-0000000000000000065_0000000000184398698 size 0 bytes.
2015-10-21 05:32:07,852 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 05:32:07,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065 expecting start txid #64
2015-10-21 05:32:07,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065
2015-10-21 05:32:07,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 05:32:07,859 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 63
2015-10-21 05:32:07,859 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000061, cpktTxId=0000000000000000061)
2015-10-21 05:32:07,890 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 65 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 05:32:07,890 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 06:32:08,294 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 06:32:08,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=66&endTxId=67&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 06:32:08,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 06:32:08,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000066-0000000000000000067_0000000000187999145 size 0 bytes.
2015-10-21 06:32:08,299 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 06:32:08,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067 expecting start txid #66
2015-10-21 06:32:08,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067
2015-10-21 06:32:08,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 06:32:08,307 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 65
2015-10-21 06:32:08,307 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2015-10-21 06:32:08,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 67 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-21 06:32:08,328 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 07:32:08,730 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 07:32:08,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=68&endTxId=69&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 07:32:08,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 07:32:08,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000068-0000000000000000069_0000000000191599581 size 0 bytes.
2015-10-21 07:32:08,735 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 07:32:08,735 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069 expecting start txid #68
2015-10-21 07:32:08,736 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069
2015-10-21 07:32:08,736 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 07:32:08,772 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 67
2015-10-21 07:32:08,773 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000065, cpktTxId=0000000000000000065)
2015-10-21 07:32:08,801 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 69 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-21 07:32:08,801 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 08:32:09,211 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 08:32:09,211 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=70&endTxId=71&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 08:32:09,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 08:32:09,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000070-0000000000000000071_0000000000195200062 size 0 bytes.
2015-10-21 08:32:09,220 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 08:32:09,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071 expecting start txid #70
2015-10-21 08:32:09,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071
2015-10-21 08:32:09,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 08:32:09,228 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 69
2015-10-21 08:32:09,228 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000067, cpktTxId=0000000000000000067)
2015-10-21 08:32:09,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 71 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 08:32:09,250 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 09:32:09,668 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 09:32:09,668 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=72&endTxId=73&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 09:32:09,672 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 09:32:09,672 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000072-0000000000000000073_0000000000198800519 size 0 bytes.
2015-10-21 09:32:09,673 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 09:32:09,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073 expecting start txid #72
2015-10-21 09:32:09,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073
2015-10-21 09:32:09,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 09:32:09,680 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 71
2015-10-21 09:32:09,680 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000069, cpktTxId=0000000000000000069)
2015-10-21 09:32:09,710 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 73 to namenode at http://master.hadoop:50070 in 0.023 seconds
2015-10-21 09:32:09,710 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 10:32:10,128 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 10:32:10,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=74&endTxId=75&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 10:32:10,132 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 10:32:10,132 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000074-0000000000000000075_0000000000202400979 size 0 bytes.
2015-10-21 10:32:10,132 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 10:32:10,132 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075 expecting start txid #74
2015-10-21 10:32:10,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075
2015-10-21 10:32:10,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 10:32:10,170 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 73
2015-10-21 10:32:10,170 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000071, cpktTxId=0000000000000000071)
2015-10-21 10:32:10,208 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 75 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-21 10:32:10,208 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 11:32:10,617 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 11:32:10,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=76&endTxId=77&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 11:32:10,621 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 11:32:10,621 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000076-0000000000000000077_0000000000206001468 size 0 bytes.
2015-10-21 11:32:10,622 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 11:32:10,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077 expecting start txid #76
2015-10-21 11:32:10,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077
2015-10-21 11:32:10,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 11:32:10,629 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 75
2015-10-21 11:32:10,629 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000073, cpktTxId=0000000000000000073)
2015-10-21 11:32:10,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 77 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 11:32:10,651 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 12:32:11,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 12:32:11,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=78&endTxId=79&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 12:32:11,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 12:32:11,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000078-0000000000000000079_0000000000209601907 size 0 bytes.
2015-10-21 12:32:11,065 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 12:32:11,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079 expecting start txid #78
2015-10-21 12:32:11,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079
2015-10-21 12:32:11,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 12:32:11,076 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 77
2015-10-21 12:32:11,076 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000075, cpktTxId=0000000000000000075)
2015-10-21 12:32:11,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 79 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-21 12:32:11,113 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 13:32:11,522 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 13:32:11,523 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=80&endTxId=81&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 13:32:11,557 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-21 13:32:11,557 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000080-0000000000000000081_0000000000213202373 size 0 bytes.
2015-10-21 13:32:11,557 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 13:32:11,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081 expecting start txid #80
2015-10-21 13:32:11,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081
2015-10-21 13:32:11,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 13:32:11,565 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 79
2015-10-21 13:32:11,565 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000077, cpktTxId=0000000000000000077)
2015-10-21 13:32:11,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 81 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 13:32:11,587 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 14:32:11,999 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 14:32:12,000 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=82&endTxId=83&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 14:32:12,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 14:32:12,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000082-0000000000000000083_0000000000216802850 size 0 bytes.
2015-10-21 14:32:12,005 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 14:32:12,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083 expecting start txid #82
2015-10-21 14:32:12,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083
2015-10-21 14:32:12,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 14:32:12,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 81
2015-10-21 14:32:12,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000079, cpktTxId=0000000000000000079)
2015-10-21 14:32:12,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 83 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-21 14:32:12,035 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 15:32:12,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 15:32:12,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=84&endTxId=85&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 15:32:12,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 15:32:12,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000084-0000000000000000085_0000000000220403303 size 0 bytes.
2015-10-21 15:32:12,458 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 15:32:12,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085 expecting start txid #84
2015-10-21 15:32:12,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085
2015-10-21 15:32:12,459 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 15:32:12,466 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 83
2015-10-21 15:32:12,466 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000081, cpktTxId=0000000000000000081)
2015-10-21 15:32:12,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 85 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-21 15:32:12,491 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 16:32:12,999 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 16:32:12,999 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=86&endTxId=87&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 16:32:13,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 16:32:13,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000086-0000000000000000087_0000000000224003850 size 0 bytes.
2015-10-21 16:32:13,004 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 16:32:13,004 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087 expecting start txid #86
2015-10-21 16:32:13,004 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087
2015-10-21 16:32:13,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 16:32:13,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 85
2015-10-21 16:32:13,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000083, cpktTxId=0000000000000000083)
2015-10-21 16:32:13,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 87 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-21 16:32:13,043 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 17:32:13,453 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 17:32:13,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=88&endTxId=89&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 17:32:13,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 17:32:13,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000088-0000000000000000089_0000000000227604304 size 0 bytes.
2015-10-21 17:32:13,458 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 17:32:13,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089 expecting start txid #88
2015-10-21 17:32:13,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089
2015-10-21 17:32:13,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 17:32:13,465 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 87
2015-10-21 17:32:13,465 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000085, cpktTxId=0000000000000000085)
2015-10-21 17:32:13,497 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 89 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-21 17:32:13,497 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 18:32:13,921 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 18:32:13,921 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=90&endTxId=91&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 18:32:13,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 18:32:13,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000090-0000000000000000091_0000000000231204772 size 0 bytes.
2015-10-21 18:32:13,926 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 18:32:13,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091 expecting start txid #90
2015-10-21 18:32:13,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091
2015-10-21 18:32:13,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 18:32:13,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 89
2015-10-21 18:32:13,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000087, cpktTxId=0000000000000000087)
2015-10-21 18:32:13,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 91 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-21 18:32:13,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 19:27:50,574 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-21 19:27:50,576 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-21 19:30:38,527 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-21 19:30:38,549 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-21 19:30:40,859 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-21 19:30:41,041 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-21 19:30:41,041 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-21 19:30:41,467 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 341@master.hadoop
2015-10-21 19:30:41,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-21 19:30:41,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-21 19:30:41,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-21 19:30:41,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-21 19:30:41,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 21 19:30:41
2015-10-21 19:30:41,780 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-21 19:30:41,780 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:30:41,782 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-21 19:30:41,782 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-21 19:30:41,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-21 19:30:41,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-21 19:30:41,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-21 19:30:41,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-21 19:30:41,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-21 19:30:41,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-21 19:30:41,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-21 19:30:42,475 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-21 19:30:42,481 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:30:42,481 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-21 19:30:42,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-21 19:30:42,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-21 19:30:42,513 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-21 19:30:42,513 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:30:42,513 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-21 19:30:42,513 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-21 19:30:42,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-21 19:30:42,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-21 19:30:42,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-21 19:30:42,523 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-21 19:30:42,523 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-21 19:30:42,523 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-21 19:30:42,550 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-21 19:30:42,550 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-21 19:30:42,851 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-21 19:30:42,864 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-21 19:30:42,892 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-21 19:30:42,895 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-21 19:30:42,895 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-21 19:30:42,895 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-21 19:30:42,937 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-21 19:30:42,938 INFO org.mortbay.log: jetty-6.1.26
2015-10-21 19:30:43,733 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-21 19:30:43,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-21 19:30:43,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-21 19:30:43,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-21 19:31:44,165 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-21 19:31:44,413 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-21 19:31:44,969 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=91&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:31:45,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-21 19:31:46,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-21 19:31:46,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000091 size 355 bytes.
2015-10-21 19:31:46,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=92&endTxId=92&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:31:46,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 68266.67 KB/s
2015-10-21 19:31:46,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000092-0000000000000000092_0000000000234777058 size 0 bytes.
2015-10-21 19:31:46,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=93&endTxId=94&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:31:46,233 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 19:31:46,233 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000093-0000000000000000094_0000000000234777080 size 0 bytes.
2015-10-21 19:31:46,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-21 19:31:46,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-21 19:31:46,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 91 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000091
2015-10-21 19:31:46,334 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-21 19:31:46,347 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-21 19:31:46,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000092 expecting start txid #92
2015-10-21 19:31:46,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000092
2015-10-21 19:31:46,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000092 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-21 19:31:46,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000093-0000000000000000094 expecting start txid #93
2015-10-21 19:31:46,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000093-0000000000000000094
2015-10-21 19:31:46,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000093-0000000000000000094 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 19:31:46,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 91
2015-10-21 19:31:46,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000089, cpktTxId=0000000000000000089)
2015-10-21 19:31:46,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 94 to namenode at http://master.hadoop:50070 in 0.062 seconds
2015-10-21 19:31:46,587 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 19:37:47,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:48,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:49,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:50,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:51,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:52,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:53,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-21 19:37:54,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-21 19:37:54,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-21 19:39:28,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-21 19:39:28,756 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-21 19:39:30,912 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-21 19:39:31,093 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-21 19:39:31,093 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-21 19:39:31,492 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 1505@master.hadoop
2015-10-21 19:39:31,727 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-21 19:39:31,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-21 19:39:31,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-21 19:39:31,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-21 19:39:31,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 21 19:39:31
2015-10-21 19:39:31,807 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-21 19:39:31,807 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:39:31,808 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-21 19:39:31,808 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-21 19:39:31,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-21 19:39:31,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-21 19:39:31,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-21 19:39:31,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-21 19:39:31,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-21 19:39:31,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-21 19:39:32,301 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-21 19:39:32,301 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:39:32,302 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-21 19:39:32,302 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-21 19:39:32,303 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-21 19:39:32,337 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-21 19:39:32,337 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-21 19:39:32,337 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-21 19:39:32,337 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-21 19:39:32,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-21 19:39:32,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-21 19:39:32,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-21 19:39:32,341 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-21 19:39:32,341 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-21 19:39:32,342 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-21 19:39:32,368 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-21 19:39:32,369 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-21 19:39:32,683 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-21 19:39:32,690 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-21 19:39:32,715 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-21 19:39:32,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-21 19:39:32,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-21 19:39:32,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-21 19:39:32,765 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-21 19:39:32,765 INFO org.mortbay.log: jetty-6.1.26
2015-10-21 19:39:33,603 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-21 19:39:33,603 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-21 19:39:33,619 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-21 19:39:33,619 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-21 19:40:33,972 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-21 19:40:34,218 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-21 19:40:34,755 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=94&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:40:34,883 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-21 19:40:35,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-21 19:40:35,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000094 size 355 bytes.
2015-10-21 19:40:35,931 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=95&endTxId=95&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:40:35,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 85333.33 KB/s
2015-10-21 19:40:35,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000095-0000000000000000095_0000000000235306781 size 0 bytes.
2015-10-21 19:40:35,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=96&endTxId=97&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 19:40:35,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 19:40:35,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000096-0000000000000000097_0000000000235306802 size 0 bytes.
2015-10-21 19:40:36,002 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-21 19:40:36,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-21 19:40:36,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 94 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000094
2015-10-21 19:40:36,050 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-21 19:40:36,069 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-21 19:40:36,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000095-0000000000000000095 expecting start txid #95
2015-10-21 19:40:36,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000095-0000000000000000095
2015-10-21 19:40:36,127 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000095-0000000000000000095 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-21 19:40:36,127 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097 expecting start txid #96
2015-10-21 19:40:36,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097
2015-10-21 19:40:36,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 19:40:36,206 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 94
2015-10-21 19:40:36,206 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000091, cpktTxId=0000000000000000091)
2015-10-21 19:40:36,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 97 to namenode at http://master.hadoop:50070 in 0.074 seconds
2015-10-21 19:40:36,320 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 20:40:36,804 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 20:40:36,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=98&endTxId=99&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 20:40:36,822 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-21 20:40:36,822 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000098-0000000000000000099_0000000000238907655 size 0 bytes.
2015-10-21 20:40:36,823 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 20:40:36,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099 expecting start txid #98
2015-10-21 20:40:36,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099
2015-10-21 20:40:36,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 20:40:36,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 97
2015-10-21 20:40:36,847 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000094, cpktTxId=0000000000000000094)
2015-10-21 20:40:36,896 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 99 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-21 20:40:36,896 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 21:40:37,332 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 21:40:37,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=100&endTxId=101&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 21:40:37,337 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 21:40:37,337 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000100-0000000000000000101_0000000000242508183 size 0 bytes.
2015-10-21 21:40:37,338 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 21:40:37,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101 expecting start txid #100
2015-10-21 21:40:37,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101
2015-10-21 21:40:37,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 21:40:37,350 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 99
2015-10-21 21:40:37,350 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000097, cpktTxId=0000000000000000097)
2015-10-21 21:40:37,424 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 101 to namenode at http://master.hadoop:50070 in 0.031 seconds
2015-10-21 21:40:37,424 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 22:40:37,840 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 22:40:37,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=102&endTxId=103&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 22:40:37,845 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 22:40:37,845 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000102-0000000000000000103_0000000000246108691 size 0 bytes.
2015-10-21 22:40:37,846 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 22:40:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103 expecting start txid #102
2015-10-21 22:40:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103
2015-10-21 22:40:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 22:40:37,857 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 101
2015-10-21 22:40:37,857 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000099, cpktTxId=0000000000000000099)
2015-10-21 22:40:37,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 103 to namenode at http://master.hadoop:50070 in 0.02 seconds
2015-10-21 22:40:37,902 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-21 23:40:38,334 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-21 23:40:38,335 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=104&endTxId=105&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-21 23:40:38,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-21 23:40:38,340 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000104-0000000000000000105_0000000000249709185 size 0 bytes.
2015-10-21 23:40:38,340 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-21 23:40:38,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105 expecting start txid #104
2015-10-21 23:40:38,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105
2015-10-21 23:40:38,341 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105 of size 42 edits # 2 loaded in 0 seconds
2015-10-21 23:40:38,348 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 103
2015-10-21 23:40:38,348 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000101, cpktTxId=0000000000000000101)
2015-10-21 23:40:38,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 105 to namenode at http://master.hadoop:50070 in 0.024 seconds
2015-10-21 23:40:38,383 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 00:40:38,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 00:40:38,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=106&endTxId=107&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 00:40:38,814 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 00:40:38,814 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000106-0000000000000000107_0000000000253309660 size 0 bytes.
2015-10-22 00:40:38,815 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 00:40:38,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107 expecting start txid #106
2015-10-22 00:40:38,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107
2015-10-22 00:40:38,816 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 00:40:38,823 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 105
2015-10-22 00:40:38,823 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000103, cpktTxId=0000000000000000103)
2015-10-22 00:40:38,862 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 107 to namenode at http://master.hadoop:50070 in 0.028 seconds
2015-10-22 00:40:38,862 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 01:40:39,284 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 01:40:39,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=108&endTxId=109&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 01:40:39,289 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 01:40:39,289 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000108-0000000000000000109_0000000000256910135 size 0 bytes.
2015-10-22 01:40:39,289 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 01:40:39,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109 expecting start txid #108
2015-10-22 01:40:39,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109
2015-10-22 01:40:39,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 01:40:39,297 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 107
2015-10-22 01:40:39,297 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000105, cpktTxId=0000000000000000105)
2015-10-22 01:40:39,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 109 to namenode at http://master.hadoop:50070 in 0.048 seconds
2015-10-22 01:40:39,363 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 01:50:09,804 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-22 01:50:09,806 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/127.0.0.1
************************************************************/
2015-10-22 01:51:07,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-22 01:51:07,987 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-22 01:51:10,153 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-22 01:51:10,333 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-22 01:51:10,333 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-22 01:51:10,743 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 6842@master.hadoop
2015-10-22 01:51:10,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-22 01:51:11,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-22 01:51:11,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-22 01:51:11,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-22 01:51:11,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 22 01:51:11
2015-10-22 01:51:11,053 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-22 01:51:11,053 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 01:51:11,055 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-22 01:51:11,055 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-22 01:51:11,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-22 01:51:11,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-22 01:51:11,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-22 01:51:11,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-22 01:51:11,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-22 01:51:11,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-22 01:51:11,550 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-22 01:51:11,551 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 01:51:11,551 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-22 01:51:11,551 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-22 01:51:11,552 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-22 01:51:11,608 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-22 01:51:11,608 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 01:51:11,608 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-22 01:51:11,608 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-22 01:51:11,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-22 01:51:11,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-22 01:51:11,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-22 01:51:11,612 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-22 01:51:11,612 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-22 01:51:11,613 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-22 01:51:11,644 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-22 01:51:11,644 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-22 01:51:11,792 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-22 01:51:11,805 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-22 01:51:11,828 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-22 01:51:11,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-22 01:51:11,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-22 01:51:11,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-22 01:51:11,874 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-22 01:51:11,874 INFO org.mortbay.log: jetty-6.1.26
2015-10-22 01:51:12,854 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-22 01:51:12,855 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-22 01:51:12,871 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-22 01:51:12,871 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-22 01:52:13,260 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-22 01:52:13,513 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-22 01:52:14,125 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=109&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 01:52:14,261 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-22 01:52:15,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-22 01:52:15,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000109 size 355 bytes.
2015-10-22 01:52:15,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=110&endTxId=110&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 01:52:15,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 102400.00 KB/s
2015-10-22 01:52:15,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000110-0000000000000000110_0000000000257606226 size 0 bytes.
2015-10-22 01:52:15,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=111&endTxId=112&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 01:52:15,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 01:52:15,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000111-0000000000000000112_0000000000257606241 size 0 bytes.
2015-10-22 01:52:15,430 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-22 01:52:15,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-22 01:52:15,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 109 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000109
2015-10-22 01:52:15,480 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-22 01:52:15,512 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-22 01:52:15,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000110 expecting start txid #110
2015-10-22 01:52:15,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000110
2015-10-22 01:52:15,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000110 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-22 01:52:15,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112 expecting start txid #111
2015-10-22 01:52:15,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112
2015-10-22 01:52:15,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 01:52:15,654 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 109
2015-10-22 01:52:15,654 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000107, cpktTxId=0000000000000000107)
2015-10-22 01:52:15,759 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 112 to namenode at http://master.hadoop:50070 in 0.072 seconds
2015-10-22 01:52:15,759 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 02:05:16,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:05:16,861 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-22 02:05:16,876 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-22 02:06:47,712 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-22 02:06:47,731 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-22 02:06:49,897 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-22 02:06:50,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-22 02:06:50,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-22 02:06:50,474 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 8217@master.hadoop
2015-10-22 02:06:50,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-22 02:06:50,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-22 02:06:50,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-22 02:06:50,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-22 02:06:50,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 22 02:06:50
2015-10-22 02:06:50,782 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-22 02:06:50,782 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:06:50,784 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-22 02:06:50,784 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-22 02:06:50,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-22 02:06:50,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-22 02:06:50,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-22 02:06:50,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-22 02:06:50,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-22 02:06:50,914 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-22 02:06:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-22 02:06:51,532 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-22 02:06:51,532 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:06:51,532 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-22 02:06:51,532 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-22 02:06:51,535 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-22 02:06:51,571 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-22 02:06:51,571 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:06:51,572 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-22 02:06:51,572 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-22 02:06:51,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-22 02:06:51,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-22 02:06:51,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-22 02:06:51,576 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-22 02:06:51,576 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-22 02:06:51,576 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-22 02:06:51,606 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-22 02:06:51,606 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-22 02:06:51,740 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-22 02:06:51,748 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-22 02:06:51,772 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-22 02:06:51,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-22 02:06:51,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-22 02:06:51,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-22 02:06:51,816 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-22 02:06:51,816 INFO org.mortbay.log: jetty-6.1.26
2015-10-22 02:06:52,825 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-22 02:06:52,825 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-22 02:06:52,842 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-22 02:06:52,842 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-22 02:07:53,060 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-22 02:07:53,317 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-22 02:07:53,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=112&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:07:53,996 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-22 02:07:55,014 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-22 02:07:55,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000112 size 355 bytes.
2015-10-22 02:07:55,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=113&endTxId=113&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:07:55,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 93090.91 KB/s
2015-10-22 02:07:55,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000113-0000000000000000113_0000000000258545871 size 0 bytes.
2015-10-22 02:07:55,036 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=114&endTxId=115&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:07:55,039 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 02:07:55,040 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000114-0000000000000000115_0000000000258545887 size 0 bytes.
2015-10-22 02:07:55,076 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-22 02:07:55,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-22 02:07:55,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 112 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000112
2015-10-22 02:07:55,138 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-22 02:07:55,154 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-22 02:07:55,166 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000113 expecting start txid #113
2015-10-22 02:07:55,166 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000113
2015-10-22 02:07:55,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000113 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-22 02:07:55,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115 expecting start txid #114
2015-10-22 02:07:55,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115
2015-10-22 02:07:55,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 02:07:55,298 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 112
2015-10-22 02:07:55,298 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000109, cpktTxId=0000000000000000109)
2015-10-22 02:07:55,401 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 115 to namenode at http://master.hadoop:50070 in 0.061 seconds
2015-10-22 02:07:55,401 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 02:30:17,459 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-22 02:30:17,460 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-22 02:31:34,604 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-22 02:31:34,625 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-22 02:31:36,914 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-22 02:31:37,091 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-22 02:31:37,091 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-22 02:31:37,497 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 9813@master.hadoop
2015-10-22 02:31:37,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-22 02:31:38,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-22 02:31:38,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-22 02:31:38,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-22 02:31:38,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 22 02:31:38
2015-10-22 02:31:38,058 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-22 02:31:38,059 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:31:38,060 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-22 02:31:38,060 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-22 02:31:38,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-22 02:31:38,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-22 02:31:38,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-22 02:31:38,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-22 02:31:38,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-22 02:31:38,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-22 02:31:38,195 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-22 02:31:38,930 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-22 02:31:38,930 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:31:38,930 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-22 02:31:38,930 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-22 02:31:38,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-22 02:31:38,964 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-22 02:31:38,964 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:31:38,964 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-22 02:31:38,964 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-22 02:31:38,974 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-22 02:31:38,974 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-22 02:31:38,974 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-22 02:31:38,979 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-22 02:31:38,980 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-22 02:31:38,980 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-22 02:31:39,007 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-22 02:31:39,007 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-22 02:31:39,156 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-22 02:31:39,160 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-22 02:31:39,202 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-22 02:31:39,225 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-22 02:31:39,225 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-22 02:31:39,225 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-22 02:31:39,331 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-22 02:31:39,331 INFO org.mortbay.log: jetty-6.1.26
2015-10-22 02:31:40,321 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-22 02:31:40,321 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-22 02:31:40,338 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-22 02:31:40,338 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-22 02:32:40,679 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-22 02:32:40,931 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-22 02:32:41,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=115&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:32:41,614 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-22 02:32:42,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-22 02:32:42,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000115 size 355 bytes.
2015-10-22 02:32:42,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=116&endTxId=116&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:32:42,675 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 93090.91 KB/s
2015-10-22 02:32:42,675 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000116-0000000000000000116_0000000000260033511 size 0 bytes.
2015-10-22 02:32:42,676 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=117&endTxId=118&storageInfo=-57:681565167:0:CID-53e1715d-0f2f-4241-8a3c-8c1633b6b4f6
2015-10-22 02:32:42,679 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 02:32:42,679 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000117-0000000000000000118_0000000000260033526 size 0 bytes.
2015-10-22 02:32:42,717 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-22 02:32:42,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-22 02:32:42,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 115 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000115
2015-10-22 02:32:42,783 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-22 02:32:42,792 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-10-22 02:32:42,805 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000116 expecting start txid #116
2015-10-22 02:32:42,807 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000116
2015-10-22 02:32:42,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000116 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-22 02:32:42,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118 expecting start txid #117
2015-10-22 02:32:42,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118
2015-10-22 02:32:42,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 02:32:42,928 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 115
2015-10-22 02:32:42,928 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000112, cpktTxId=0000000000000000112)
2015-10-22 02:32:43,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 118 to namenode at http://master.hadoop:50070 in 0.072 seconds
2015-10-22 02:32:43,047 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 02:49:44,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:49:45,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:49:46,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:49:47,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:49:48,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master.hadoop/10.64.252.124:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-22 02:49:49,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-22 02:49:49,065 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-22 02:52:48,054 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-22 02:52:48,074 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-22 02:52:50,235 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-22 02:52:50,409 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-22 02:52:50,409 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-22 02:52:50,812 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 11346@master.hadoop
2015-10-22 02:52:50,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-22 02:52:50,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-22 02:52:50,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-22 02:52:50,866 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-22 02:52:50,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 22 02:52:50
2015-10-22 02:52:50,870 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-22 02:52:50,870 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:52:50,872 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-22 02:52:50,872 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-22 02:52:50,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-22 02:52:50,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-22 02:52:50,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-22 02:52:50,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-22 02:52:50,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-22 02:52:50,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-22 02:52:51,285 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-22 02:52:51,285 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:52:51,285 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-22 02:52:51,285 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-22 02:52:51,286 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-22 02:52:51,301 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-22 02:52:51,301 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-22 02:52:51,301 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-22 02:52:51,301 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-22 02:52:51,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-22 02:52:51,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-22 02:52:51,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-22 02:52:51,305 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-22 02:52:51,306 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-22 02:52:51,306 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-22 02:52:51,319 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-22 02:52:51,319 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-22 02:52:51,387 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-22 02:52:51,391 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-22 02:52:51,403 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-22 02:52:51,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-22 02:52:51,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-22 02:52:51,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-22 02:52:51,426 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-22 02:52:51,426 INFO org.mortbay.log: jetty-6.1.26
2015-10-22 02:52:52,558 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-22 02:52:52,559 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-22 02:52:52,577 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-22 02:52:52,577 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-22 02:53:52,896 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-22 02:53:53,155 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-22 02:53:53,641 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=0&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 02:53:53,827 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-22 02:53:54,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-10-22 02:53:54,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 355 bytes.
2015-10-22 02:53:54,584 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 02:53:54,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-22 02:53:54,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000261305435 size 0 bytes.
2015-10-22 02:53:54,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-10-22 02:53:54,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-22 02:53:54,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000000
2015-10-22 02:53:54,764 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-22 02:53:54,774 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 02:53:54,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2015-10-22 02:53:54,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2015-10-22 02:53:54,803 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 02:53:54,902 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary
2015-10-22 02:53:54,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://master.hadoop:50070 in 0.03 seconds
2015-10-22 02:53:54,941 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 03:53:55,364 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 03:53:55,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 03:53:55,388 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 03:53:55,388 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000264906215 size 0 bytes.
2015-10-22 03:53:55,389 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 03:53:55,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2015-10-22 03:53:55,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004
2015-10-22 03:53:55,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 03:53:55,453 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2015-10-22 03:53:55,453 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2015-10-22 03:53:55,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4 to namenode at http://master.hadoop:50070 in 0.04 seconds
2015-10-22 03:53:55,502 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 04:53:55,912 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 04:53:55,913 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=5&endTxId=6&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 04:53:55,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 04:53:55,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000005-0000000000000000006_0000000000268506763 size 0 bytes.
2015-10-22 04:53:55,918 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 04:53:55,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000006 expecting start txid #5
2015-10-22 04:53:55,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000006
2015-10-22 04:53:55,919 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000006 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 04:53:55,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2015-10-22 04:53:55,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2015-10-22 04:53:55,940 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 6 to namenode at http://master.hadoop:50070 in 0.009 seconds
2015-10-22 04:53:55,940 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 05:53:56,349 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 05:53:56,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=7&endTxId=8&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 05:53:56,354 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 05:53:56,354 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000007-0000000000000000008_0000000000272107200 size 0 bytes.
2015-10-22 05:53:56,355 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 05:53:56,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000007-0000000000000000008 expecting start txid #7
2015-10-22 05:53:56,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000007-0000000000000000008
2015-10-22 05:53:56,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000007-0000000000000000008 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 05:53:56,366 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 6
2015-10-22 05:53:56,366 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2015-10-22 05:53:56,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 8 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-22 05:53:56,380 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 06:53:56,787 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 06:53:56,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=9&endTxId=10&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 06:53:56,792 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 06:53:56,792 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000009-0000000000000000010_0000000000275707638 size 0 bytes.
2015-10-22 06:53:56,793 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 06:53:56,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000009-0000000000000000010 expecting start txid #9
2015-10-22 06:53:56,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000009-0000000000000000010
2015-10-22 06:53:56,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000009-0000000000000000010 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 06:53:56,801 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 8
2015-10-22 06:53:56,801 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000006, cpktTxId=0000000000000000006)
2015-10-22 06:53:56,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 10 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-22 06:53:56,821 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 07:53:57,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 07:53:57,234 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=11&endTxId=12&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 07:53:57,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 07:53:57,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000011-0000000000000000012_0000000000279308085 size 0 bytes.
2015-10-22 07:53:57,243 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 07:53:57,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000011-0000000000000000012 expecting start txid #11
2015-10-22 07:53:57,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000011-0000000000000000012
2015-10-22 07:53:57,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000011-0000000000000000012 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 07:53:57,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 10
2015-10-22 07:53:57,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000008, cpktTxId=0000000000000000008)
2015-10-22 07:53:57,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 12 to namenode at http://master.hadoop:50070 in 0.009 seconds
2015-10-22 07:53:57,264 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 08:53:57,677 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 08:53:57,678 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=13&endTxId=14&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 08:53:57,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 08:53:57,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000013-0000000000000000014_0000000000282908528 size 0 bytes.
2015-10-22 08:53:57,683 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 08:53:57,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014 expecting start txid #13
2015-10-22 08:53:57,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014
2015-10-22 08:53:57,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 08:53:57,695 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 12
2015-10-22 08:53:57,695 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000010, cpktTxId=0000000000000000010)
2015-10-22 08:53:57,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 14 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 08:53:57,710 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 09:53:58,125 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 09:53:58,125 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=15&endTxId=16&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 09:53:58,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 09:53:58,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000015-0000000000000000016_0000000000286508976 size 0 bytes.
2015-10-22 09:53:58,130 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 09:53:58,130 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000016 expecting start txid #15
2015-10-22 09:53:58,130 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000016
2015-10-22 09:53:58,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000015-0000000000000000016 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 09:53:58,144 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 14
2015-10-22 09:53:58,144 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2015-10-22 09:53:58,167 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 16 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-22 09:53:58,167 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 10:53:58,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 10:53:58,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=17&endTxId=18&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 10:53:58,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 10:53:58,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000017-0000000000000000018_0000000000290109431 size 0 bytes.
2015-10-22 10:53:58,586 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 10:53:58,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000018 expecting start txid #17
2015-10-22 10:53:58,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000018
2015-10-22 10:53:58,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000018 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 10:53:58,593 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 16
2015-10-22 10:53:58,594 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2015-10-22 10:53:58,608 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 18 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 10:53:58,608 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 11:53:59,012 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 11:53:59,012 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=19&endTxId=20&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 11:53:59,017 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 11:53:59,017 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000019-0000000000000000020_0000000000293709863 size 0 bytes.
2015-10-22 11:53:59,018 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 11:53:59,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000019-0000000000000000020 expecting start txid #19
2015-10-22 11:53:59,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000019-0000000000000000020
2015-10-22 11:53:59,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000019-0000000000000000020 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 11:53:59,025 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 18
2015-10-22 11:53:59,025 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000016, cpktTxId=0000000000000000016)
2015-10-22 11:53:59,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 20 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 11:53:59,046 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 12:53:59,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 12:53:59,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=21&endTxId=22&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 12:53:59,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 12:53:59,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000021-0000000000000000022_0000000000297310303 size 0 bytes.
2015-10-22 12:53:59,457 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 12:53:59,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000021-0000000000000000022 expecting start txid #21
2015-10-22 12:53:59,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000021-0000000000000000022
2015-10-22 12:53:59,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000021-0000000000000000022 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 12:53:59,465 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 20
2015-10-22 12:53:59,465 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000018, cpktTxId=0000000000000000018)
2015-10-22 12:53:59,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 22 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 12:53:59,479 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 13:53:59,894 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 13:53:59,895 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=23&endTxId=24&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 13:53:59,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 13:53:59,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000023-0000000000000000024_0000000000300910745 size 0 bytes.
2015-10-22 13:53:59,902 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 13:53:59,902 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000023-0000000000000000024 expecting start txid #23
2015-10-22 13:53:59,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000023-0000000000000000024
2015-10-22 13:53:59,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000023-0000000000000000024 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 13:53:59,910 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 22
2015-10-22 13:53:59,911 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000020, cpktTxId=0000000000000000020)
2015-10-22 13:53:59,932 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 24 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 13:53:59,932 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 14:54:00,342 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 14:54:00,343 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=25&endTxId=26&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 14:54:00,347 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 14:54:00,347 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000025-0000000000000000026_0000000000304511193 size 0 bytes.
2015-10-22 14:54:00,348 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 14:54:00,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000026 expecting start txid #25
2015-10-22 14:54:00,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000026
2015-10-22 14:54:00,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000026 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 14:54:00,356 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 24
2015-10-22 14:54:00,356 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000022, cpktTxId=0000000000000000022)
2015-10-22 14:54:00,377 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 26 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-22 14:54:00,377 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 15:54:00,789 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 15:54:00,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=27&endTxId=28&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 15:54:00,794 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 15:54:00,795 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000027-0000000000000000028_0000000000308111640 size 0 bytes.
2015-10-22 15:54:00,795 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 15:54:00,795 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000027-0000000000000000028 expecting start txid #27
2015-10-22 15:54:00,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000027-0000000000000000028
2015-10-22 15:54:00,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000027-0000000000000000028 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 15:54:00,803 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 26
2015-10-22 15:54:00,803 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000024, cpktTxId=0000000000000000024)
2015-10-22 15:54:00,819 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 28 to namenode at http://master.hadoop:50070 in 0.01 seconds
2015-10-22 15:54:00,819 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 16:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 16:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=29&endTxId=30&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 16:54:01,237 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 16:54:01,237 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000029-0000000000000000030_0000000000311712081 size 0 bytes.
2015-10-22 16:54:01,237 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 16:54:01,237 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000029-0000000000000000030 expecting start txid #29
2015-10-22 16:54:01,237 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000029-0000000000000000030
2015-10-22 16:54:01,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000029-0000000000000000030 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 16:54:01,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 28
2015-10-22 16:54:01,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000026, cpktTxId=0000000000000000026)
2015-10-22 16:54:01,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 30 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-22 16:54:01,274 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 17:54:01,692 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 17:54:01,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=31&endTxId=32&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 17:54:01,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-22 17:54:01,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000031-0000000000000000032_0000000000315312543 size 0 bytes.
2015-10-22 17:54:01,705 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 17:54:01,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000031-0000000000000000032 expecting start txid #31
2015-10-22 17:54:01,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000031-0000000000000000032
2015-10-22 17:54:01,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000031-0000000000000000032 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 17:54:01,712 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 30
2015-10-22 17:54:01,713 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000028, cpktTxId=0000000000000000028)
2015-10-22 17:54:01,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 32 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-22 17:54:01,732 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 355
2015-10-22 18:54:02,141 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 18:54:02,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=33&endTxId=35&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 18:54:02,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 18:54:02,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000033-0000000000000000035_0000000000318912992 size 0 bytes.
2015-10-22 18:54:02,146 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 18:54:02,147 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000033-0000000000000000035 expecting start txid #33
2015-10-22 18:54:02,147 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000033-0000000000000000035
2015-10-22 18:54:02,165 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000033-0000000000000000035 of size 119 edits # 3 loaded in 0 seconds
2015-10-22 18:54:02,180 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 32
2015-10-22 18:54:02,181 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000030, cpktTxId=0000000000000000030)
2015-10-22 18:54:02,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 35 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-22 18:54:02,197 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-22 19:54:02,597 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 19:54:02,597 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=36&endTxId=37&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 19:54:02,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 19:54:02,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000036-0000000000000000037_0000000000322513448 size 0 bytes.
2015-10-22 19:54:02,603 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 19:54:02,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 expecting start txid #36
2015-10-22 19:54:02,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037
2015-10-22 19:54:02,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 19:54:02,611 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 35
2015-10-22 19:54:02,611 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000032, cpktTxId=0000000000000000032)
2015-10-22 19:54:02,628 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 37 to namenode at http://master.hadoop:50070 in 0.011 seconds
2015-10-22 19:54:02,628 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-22 20:54:03,021 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 20:54:03,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=38&endTxId=39&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 20:54:03,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 20:54:03,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000038-0000000000000000039_0000000000326113872 size 0 bytes.
2015-10-22 20:54:03,026 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 20:54:03,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 expecting start txid #38
2015-10-22 20:54:03,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039
2015-10-22 20:54:03,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000038-0000000000000000039 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 20:54:03,040 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 37
2015-10-22 20:54:03,040 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000035, cpktTxId=0000000000000000035)
2015-10-22 20:54:03,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 39 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-22 20:54:03,060 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-22 21:54:03,466 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 21:54:03,467 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=40&endTxId=41&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 21:54:03,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 21:54:03,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000040-0000000000000000041_0000000000329714317 size 0 bytes.
2015-10-22 21:54:03,474 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 21:54:03,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 expecting start txid #40
2015-10-22 21:54:03,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041
2015-10-22 21:54:03,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000040-0000000000000000041 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 21:54:03,482 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 39
2015-10-22 21:54:03,482 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000037, cpktTxId=0000000000000000037)
2015-10-22 21:54:03,499 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 41 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-22 21:54:03,499 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-22 22:54:03,901 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 22:54:03,901 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=42&endTxId=43&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 22:54:03,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 22:54:03,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000042-0000000000000000043_0000000000333314752 size 0 bytes.
2015-10-22 22:54:03,906 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 22:54:03,906 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 expecting start txid #42
2015-10-22 22:54:03,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043
2015-10-22 22:54:03,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000042-0000000000000000043 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 22:54:03,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 41
2015-10-22 22:54:03,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000039, cpktTxId=0000000000000000039)
2015-10-22 22:54:03,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 43 to namenode at http://master.hadoop:50070 in 0.042 seconds
2015-10-22 22:54:03,963 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-22 23:54:04,377 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-22 23:54:04,378 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=44&endTxId=45&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-22 23:54:04,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-22 23:54:04,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000044-0000000000000000045_0000000000336915228 size 0 bytes.
2015-10-22 23:54:04,386 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-22 23:54:04,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 expecting start txid #44
2015-10-22 23:54:04,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045
2015-10-22 23:54:04,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000045 of size 42 edits # 2 loaded in 0 seconds
2015-10-22 23:54:04,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2015-10-22 23:54:04,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000041, cpktTxId=0000000000000000041)
2015-10-22 23:54:04,412 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 45 to namenode at http://master.hadoop:50070 in 0.012 seconds
2015-10-22 23:54:04,412 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 00:54:04,820 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 00:54:04,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=46&endTxId=47&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 00:54:04,824 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 00:54:04,824 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000046-0000000000000000047_0000000000340515671 size 0 bytes.
2015-10-23 00:54:04,825 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 00:54:04,825 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 expecting start txid #46
2015-10-23 00:54:04,825 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047
2015-10-23 00:54:04,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000046-0000000000000000047 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 00:54:04,832 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 45
2015-10-23 00:54:04,833 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2015-10-23 00:54:04,853 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 47 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 00:54:04,854 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 01:54:05,261 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 01:54:05,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=48&endTxId=49&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 01:54:05,266 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 01:54:05,266 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000048-0000000000000000049_0000000000344116112 size 0 bytes.
2015-10-23 01:54:05,267 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 01:54:05,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049 expecting start txid #48
2015-10-23 01:54:05,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049
2015-10-23 01:54:05,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000048-0000000000000000049 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 01:54:05,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 47
2015-10-23 01:54:05,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000045, cpktTxId=0000000000000000045)
2015-10-23 01:54:05,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 49 to namenode at http://master.hadoop:50070 in 0.021 seconds
2015-10-23 01:54:05,306 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 02:25:02,034 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-23 02:25:02,036 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-23 02:25:57,682 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-23 02:25:57,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-23 02:25:59,947 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-23 02:26:00,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-23 02:26:00,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-23 02:26:00,574 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 17596@master.hadoop
2015-10-23 02:26:00,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-23 02:26:00,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-23 02:26:00,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-23 02:26:00,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-23 02:26:00,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 23 02:26:00
2015-10-23 02:26:00,912 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-23 02:26:00,913 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:26:00,914 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-23 02:26:00,914 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-23 02:26:00,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-23 02:26:00,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-23 02:26:00,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-23 02:26:00,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-23 02:26:00,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-23 02:26:00,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-23 02:26:01,637 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-23 02:26:01,637 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:26:01,638 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-23 02:26:01,638 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-23 02:26:01,639 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-23 02:26:01,693 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-23 02:26:01,693 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:26:01,693 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-23 02:26:01,693 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-23 02:26:01,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-23 02:26:01,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-23 02:26:01,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-23 02:26:01,708 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-23 02:26:01,708 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-23 02:26:01,708 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-23 02:26:01,739 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-23 02:26:01,739 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-23 02:26:01,898 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-23 02:26:01,910 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-23 02:26:01,954 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-23 02:26:01,977 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-23 02:26:01,977 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-23 02:26:01,978 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-23 02:26:02,087 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-23 02:26:02,088 INFO org.mortbay.log: jetty-6.1.26
2015-10-23 02:26:03,121 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-23 02:26:03,121 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-23 02:26:03,137 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-23 02:26:03,137 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-23 02:26:31,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-10-23 02:26:31,493 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master.hadoop/10.64.252.124
************************************************************/
2015-10-23 02:29:43,569 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master.hadoop/10.64.252.124
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = /usr/software/hadoop-2.5.2/etc/hadoop:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-net-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hadoop-auth-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/common/hadoop-common-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/hdfs/hadoop-hdfs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/activation-1.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-client-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-api-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/yarn/hadoop-yarn-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2-tests.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.2.jar:/usr/software/hadoop-2.5.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r cc72e9b000545b86b75a61f4835eb86d57bfafc0; compiled by 'jenkins' on 2014-11-14T23:45Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2015-10-23 02:29:43,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-10-23 02:29:45,788 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-23 02:29:45,975 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-23 02:29:45,976 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-10-23 02:29:46,419 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/in_use.lock acquired by nodename 18512@master.hadoop
2015-10-23 02:29:46,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-10-23 02:29:46,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-10-23 02:29:46,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-10-23 02:29:46,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-10-23 02:29:46,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Oct 23 02:29:46
2015-10-23 02:29:46,750 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-10-23 02:29:46,750 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:29:46,752 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2015-10-23 02:29:46,752 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-10-23 02:29:46,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-10-23 02:29:46,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-10-23 02:29:46,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = sihhuang (auth:SIMPLE)
2015-10-23 02:29:46,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-10-23 02:29:46,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-10-23 02:29:46,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-10-23 02:29:46,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-10-23 02:29:47,395 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-10-23 02:29:47,395 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:29:47,395 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2015-10-23 02:29:47,395 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-10-23 02:29:47,397 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-10-23 02:29:47,432 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-10-23 02:29:47,432 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-10-23 02:29:47,432 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2015-10-23 02:29:47,433 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-10-23 02:29:47,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-10-23 02:29:47,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-10-23 02:29:47,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-10-23 02:29:47,445 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-10-23 02:29:47,447 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-10-23 02:29:47,447 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-10-23 02:29:47,471 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-10-23 02:29:47,471 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-10-23 02:29:47,620 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-10-23 02:29:47,625 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-10-23 02:29:47,653 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-10-23 02:29:47,656 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-10-23 02:29:47,656 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-10-23 02:29:47,656 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-10-23 02:29:47,704 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-10-23 02:29:47,704 INFO org.mortbay.log: jetty-6.1.26
2015-10-23 02:29:48,717 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-10-23 02:29:48,717 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-10-23 02:29:48,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-10-23 02:29:48,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-10-23 02:30:49,036 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-10-23 02:30:49,311 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2015-10-23 02:30:49,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getimage=1&txid=49&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 02:30:50,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-10-23 02:30:51,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-23 02:30:51,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000049 size 433 bytes.
2015-10-23 02:30:51,405 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=50&endTxId=50&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 02:30:51,419 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 93090.91 KB/s
2015-10-23 02:30:51,419 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000050-0000000000000000050_0000000000346322255 size 0 bytes.
2015-10-23 02:30:51,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=51&endTxId=51&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 02:30:51,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 85333.33 KB/s
2015-10-23 02:30:51,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000051-0000000000000000051_0000000000346322271 size 0 bytes.
2015-10-23 02:30:51,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=52&endTxId=53&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 02:30:51,464 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-23 02:30:51,464 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000052-0000000000000000053_0000000000346322287 size 0 bytes.
2015-10-23 02:30:51,499 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 2 INodes.
2015-10-23 02:30:51,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-10-23 02:30:51,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 49 from /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000049
2015-10-23 02:30:51,560 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-10-23 02:30:51,576 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 3 stream(s).
2015-10-23 02:30:51,591 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000050 expecting start txid #50
2015-10-23 02:30:51,591 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000050
2015-10-23 02:30:51,645 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000050-0000000000000000050 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-23 02:30:51,645 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051 expecting start txid #51
2015-10-23 02:30:51,645 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051
2015-10-23 02:30:51,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000051-0000000000000000051 of size 1048576 edits # 1 loaded in 0 seconds
2015-10-23 02:30:51,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 expecting start txid #52
2015-10-23 02:30:51,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053
2015-10-23 02:30:51,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000052-0000000000000000053 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 02:30:51,742 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 49
2015-10-23 02:30:51,743 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000047, cpktTxId=0000000000000000047)
2015-10-23 02:30:51,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 53 to namenode at http://master.hadoop:50070 in 0.046 seconds
2015-10-23 02:30:51,810 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 03:30:52,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 03:30:52,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=54&endTxId=55&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 03:30:52,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-23 03:30:52,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000054-0000000000000000055_0000000000349923093 size 0 bytes.
2015-10-23 03:30:52,256 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 03:30:52,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055 expecting start txid #54
2015-10-23 03:30:52,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055
2015-10-23 03:30:52,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000054-0000000000000000055 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 03:30:52,283 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 53
2015-10-23 03:30:52,286 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000049, cpktTxId=0000000000000000049)
2015-10-23 03:30:52,335 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 55 to namenode at http://master.hadoop:50070 in 0.031 seconds
2015-10-23 03:30:52,336 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 04:30:52,759 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 04:30:52,759 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=56&endTxId=57&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 04:30:52,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 04:30:52,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000056-0000000000000000057_0000000000353523610 size 0 bytes.
2015-10-23 04:30:52,765 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 04:30:52,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057 expecting start txid #56
2015-10-23 04:30:52,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057
2015-10-23 04:30:52,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000056-0000000000000000057 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 04:30:52,780 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 55
2015-10-23 04:30:52,780 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000053, cpktTxId=0000000000000000053)
2015-10-23 04:30:52,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 57 to namenode at http://master.hadoop:50070 in 0.023 seconds
2015-10-23 04:30:52,818 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 05:30:53,233 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 05:30:53,234 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=58&endTxId=59&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 05:30:53,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 05:30:53,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000058-0000000000000000059_0000000000357124084 size 0 bytes.
2015-10-23 05:30:53,239 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 05:30:53,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059 expecting start txid #58
2015-10-23 05:30:53,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059
2015-10-23 05:30:53,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000058-0000000000000000059 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 05:30:53,281 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 57
2015-10-23 05:30:53,281 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000055, cpktTxId=0000000000000000055)
2015-10-23 05:30:53,324 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 59 to namenode at http://master.hadoop:50070 in 0.019 seconds
2015-10-23 05:30:53,325 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 06:30:53,738 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 06:30:53,738 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=60&endTxId=61&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 06:30:53,748 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 06:30:53,748 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000060-0000000000000000061_0000000000360724589 size 0 bytes.
2015-10-23 06:30:53,748 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 06:30:53,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061 expecting start txid #60
2015-10-23 06:30:53,749 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061
2015-10-23 06:30:53,749 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000060-0000000000000000061 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 06:30:53,760 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 59
2015-10-23 06:30:53,761 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000057, cpktTxId=0000000000000000057)
2015-10-23 06:30:53,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 61 to namenode at http://master.hadoop:50070 in 0.03 seconds
2015-10-23 06:30:53,815 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 07:30:54,223 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 07:30:54,223 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=62&endTxId=63&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 07:30:54,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 07:30:54,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000062-0000000000000000063_0000000000364325074 size 0 bytes.
2015-10-23 07:30:54,228 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 07:30:54,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063 expecting start txid #62
2015-10-23 07:30:54,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063
2015-10-23 07:30:54,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000062-0000000000000000063 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 07:30:54,235 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 61
2015-10-23 07:30:54,235 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000059, cpktTxId=0000000000000000059)
2015-10-23 07:30:54,256 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 63 to namenode at http://master.hadoop:50070 in 0.013 seconds
2015-10-23 07:30:54,257 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 08:30:54,651 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 08:30:54,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=64&endTxId=65&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 08:30:54,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 08:30:54,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000064-0000000000000000065_0000000000367925503 size 0 bytes.
2015-10-23 08:30:54,657 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 08:30:54,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065 expecting start txid #64
2015-10-23 08:30:54,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065
2015-10-23 08:30:54,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000064-0000000000000000065 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 08:30:54,701 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 63
2015-10-23 08:30:54,701 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000061, cpktTxId=0000000000000000061)
2015-10-23 08:30:54,723 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 65 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 08:30:54,724 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 09:30:55,181 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 09:30:55,182 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=66&endTxId=67&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 09:30:55,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.10s at 0.00 KB/s
2015-10-23 09:30:55,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000066-0000000000000000067_0000000000371526032 size 0 bytes.
2015-10-23 09:30:55,284 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 09:30:55,284 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067 expecting start txid #66
2015-10-23 09:30:55,284 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067
2015-10-23 09:30:55,284 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000066-0000000000000000067 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 09:30:55,387 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 65
2015-10-23 09:30:55,387 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2015-10-23 09:30:55,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 67 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 09:30:55,504 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 10:30:55,926 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 10:30:55,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=68&endTxId=69&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 10:30:55,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 10:30:55,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000068-0000000000000000069_0000000000375126777 size 0 bytes.
2015-10-23 10:30:55,931 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 10:30:55,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069 expecting start txid #68
2015-10-23 10:30:55,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069
2015-10-23 10:30:55,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000068-0000000000000000069 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 10:30:55,938 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 67
2015-10-23 10:30:55,938 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000065, cpktTxId=0000000000000000065)
2015-10-23 10:30:55,961 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 69 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-23 10:30:55,961 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 11:30:56,356 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 11:30:56,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=70&endTxId=71&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 11:30:56,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-23 11:30:56,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000070-0000000000000000071_0000000000378727207 size 0 bytes.
2015-10-23 11:30:56,390 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 11:30:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071 expecting start txid #70
2015-10-23 11:30:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071
2015-10-23 11:30:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000070-0000000000000000071 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 11:30:56,400 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 69
2015-10-23 11:30:56,401 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000067, cpktTxId=0000000000000000067)
2015-10-23 11:30:56,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 71 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 11:30:56,425 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 12:30:56,827 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 12:30:56,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=72&endTxId=73&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 12:30:56,834 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 12:30:56,834 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000072-0000000000000000073_0000000000382327678 size 0 bytes.
2015-10-23 12:30:56,835 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 12:30:56,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073 expecting start txid #72
2015-10-23 12:30:56,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073
2015-10-23 12:30:56,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000072-0000000000000000073 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 12:30:56,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 71
2015-10-23 12:30:56,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000069, cpktTxId=0000000000000000069)
2015-10-23 12:30:56,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 73 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-23 12:30:56,866 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 13:30:57,285 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 13:30:57,286 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=74&endTxId=75&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 13:30:57,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 13:30:57,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000074-0000000000000000075_0000000000385928136 size 0 bytes.
2015-10-23 13:30:57,292 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 13:30:57,292 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075 expecting start txid #74
2015-10-23 13:30:57,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075
2015-10-23 13:30:57,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000074-0000000000000000075 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 13:30:57,302 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 73
2015-10-23 13:30:57,302 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000071, cpktTxId=0000000000000000071)
2015-10-23 13:30:57,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 75 to namenode at http://master.hadoop:50070 in 0.021 seconds
2015-10-23 13:30:57,334 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 14:30:57,768 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 14:30:57,769 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=76&endTxId=77&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 14:30:57,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 14:30:57,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000076-0000000000000000077_0000000000389528619 size 0 bytes.
2015-10-23 14:30:57,774 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 14:30:57,774 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077 expecting start txid #76
2015-10-23 14:30:57,774 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077
2015-10-23 14:30:57,774 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000076-0000000000000000077 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 14:30:57,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 75
2015-10-23 14:30:57,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000073, cpktTxId=0000000000000000073)
2015-10-23 14:30:57,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 77 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-23 14:30:57,811 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 15:30:58,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 15:30:58,215 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=78&endTxId=79&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 15:30:58,219 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 15:30:58,219 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000078-0000000000000000079_0000000000393129066 size 0 bytes.
2015-10-23 15:30:58,220 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 15:30:58,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079 expecting start txid #78
2015-10-23 15:30:58,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079
2015-10-23 15:30:58,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000078-0000000000000000079 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 15:30:58,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 77
2015-10-23 15:30:58,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000075, cpktTxId=0000000000000000075)
2015-10-23 15:30:58,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 79 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-23 15:30:58,254 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 16:30:58,650 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 16:30:58,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=80&endTxId=81&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 16:30:58,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 16:30:58,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000080-0000000000000000081_0000000000396729501 size 0 bytes.
2015-10-23 16:30:58,657 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 16:30:58,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081 expecting start txid #80
2015-10-23 16:30:58,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081
2015-10-23 16:30:58,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000080-0000000000000000081 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 16:30:58,665 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 79
2015-10-23 16:30:58,665 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000077, cpktTxId=0000000000000000077)
2015-10-23 16:30:58,688 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 81 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 16:30:58,689 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 17:30:59,135 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 17:30:59,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=82&endTxId=83&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 17:30:59,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 17:30:59,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000082-0000000000000000083_0000000000400329986 size 0 bytes.
2015-10-23 17:30:59,140 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 17:30:59,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083 expecting start txid #82
2015-10-23 17:30:59,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083
2015-10-23 17:30:59,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000082-0000000000000000083 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 17:30:59,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 81
2015-10-23 17:30:59,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000079, cpktTxId=0000000000000000079)
2015-10-23 17:30:59,174 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 83 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-23 17:30:59,174 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 18:30:59,573 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 18:30:59,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=84&endTxId=85&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 18:30:59,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 18:30:59,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000084-0000000000000000085_0000000000403930424 size 0 bytes.
2015-10-23 18:30:59,578 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 18:30:59,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085 expecting start txid #84
2015-10-23 18:30:59,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085
2015-10-23 18:30:59,579 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000084-0000000000000000085 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 18:30:59,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 83
2015-10-23 18:30:59,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000081, cpktTxId=0000000000000000081)
2015-10-23 18:30:59,625 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 85 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-23 18:30:59,625 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 19:31:00,025 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 19:31:00,026 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=86&endTxId=87&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 19:31:00,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 19:31:00,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000086-0000000000000000087_0000000000407530876 size 0 bytes.
2015-10-23 19:31:00,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 19:31:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087 expecting start txid #86
2015-10-23 19:31:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087
2015-10-23 19:31:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000086-0000000000000000087 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 19:31:00,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 85
2015-10-23 19:31:00,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000083, cpktTxId=0000000000000000083)
2015-10-23 19:31:00,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 87 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-23 19:31:00,067 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 20:31:00,475 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 20:31:00,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=88&endTxId=89&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 20:31:00,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 20:31:00,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000088-0000000000000000089_0000000000411131326 size 0 bytes.
2015-10-23 20:31:00,482 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 20:31:00,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089 expecting start txid #88
2015-10-23 20:31:00,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089
2015-10-23 20:31:00,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000088-0000000000000000089 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 20:31:00,491 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 87
2015-10-23 20:31:00,491 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000085, cpktTxId=0000000000000000085)
2015-10-23 20:31:00,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 89 to namenode at http://master.hadoop:50070 in 0.025 seconds
2015-10-23 20:31:00,525 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 21:31:00,946 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 21:31:00,947 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=90&endTxId=91&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 21:31:00,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 21:31:00,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000090-0000000000000000091_0000000000414731797 size 0 bytes.
2015-10-23 21:31:00,952 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 21:31:00,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091 expecting start txid #90
2015-10-23 21:31:00,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091
2015-10-23 21:31:00,953 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000090-0000000000000000091 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 21:31:00,960 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 89
2015-10-23 21:31:00,960 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000087, cpktTxId=0000000000000000087)
2015-10-23 21:31:00,993 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 91 to namenode at http://master.hadoop:50070 in 0.025 seconds
2015-10-23 21:31:00,994 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 22:31:01,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 22:31:01,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=92&endTxId=93&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 22:31:01,401 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 22:31:01,401 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000092-0000000000000000093_0000000000418332248 size 0 bytes.
2015-10-23 22:31:01,402 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 22:31:01,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000093 expecting start txid #92
2015-10-23 22:31:01,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000093
2015-10-23 22:31:01,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000092-0000000000000000093 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 22:31:01,410 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 91
2015-10-23 22:31:01,410 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000089, cpktTxId=0000000000000000089)
2015-10-23 22:31:01,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 93 to namenode at http://master.hadoop:50070 in 0.046 seconds
2015-10-23 22:31:01,465 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-23 23:31:01,882 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-23 23:31:01,883 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=94&endTxId=95&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-23 23:31:01,887 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-23 23:31:01,887 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000094-0000000000000000095_0000000000421932733 size 0 bytes.
2015-10-23 23:31:01,887 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-23 23:31:01,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000094-0000000000000000095 expecting start txid #94
2015-10-23 23:31:01,888 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000094-0000000000000000095
2015-10-23 23:31:01,888 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000094-0000000000000000095 of size 42 edits # 2 loaded in 0 seconds
2015-10-23 23:31:01,895 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 93
2015-10-23 23:31:01,895 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000091, cpktTxId=0000000000000000091)
2015-10-23 23:31:01,920 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 95 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-23 23:31:01,920 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 00:31:02,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 00:31:02,319 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=96&endTxId=97&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 00:31:02,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 00:31:02,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000096-0000000000000000097_0000000000425533169 size 0 bytes.
2015-10-24 00:31:02,323 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 00:31:02,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097 expecting start txid #96
2015-10-24 00:31:02,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097
2015-10-24 00:31:02,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000096-0000000000000000097 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 00:31:02,331 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 95
2015-10-24 00:31:02,331 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000093, cpktTxId=0000000000000000093)
2015-10-24 00:31:02,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 97 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-24 00:31:02,356 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 01:31:02,780 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 01:31:02,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=98&endTxId=99&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 01:31:02,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 01:31:02,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000098-0000000000000000099_0000000000429133631 size 0 bytes.
2015-10-24 01:31:02,786 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 01:31:02,787 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099 expecting start txid #98
2015-10-24 01:31:02,787 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099
2015-10-24 01:31:02,787 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000098-0000000000000000099 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 01:31:02,832 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 97
2015-10-24 01:31:02,833 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000095, cpktTxId=0000000000000000095)
2015-10-24 01:31:02,865 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 99 to namenode at http://master.hadoop:50070 in 0.023 seconds
2015-10-24 01:31:02,865 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 02:31:03,266 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 02:31:03,266 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=100&endTxId=101&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 02:31:03,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 02:31:03,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000100-0000000000000000101_0000000000432734117 size 0 bytes.
2015-10-24 02:31:03,271 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 02:31:03,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101 expecting start txid #100
2015-10-24 02:31:03,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101
2015-10-24 02:31:03,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000100-0000000000000000101 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 02:31:03,279 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 99
2015-10-24 02:31:03,279 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000097, cpktTxId=0000000000000000097)
2015-10-24 02:31:03,303 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 101 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-24 02:31:03,304 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 03:31:03,707 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 03:31:03,707 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=102&endTxId=103&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 03:31:03,713 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 03:31:03,713 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000102-0000000000000000103_0000000000436334558 size 0 bytes.
2015-10-24 03:31:03,714 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 03:31:03,714 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103 expecting start txid #102
2015-10-24 03:31:03,714 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103
2015-10-24 03:31:03,714 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000102-0000000000000000103 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 03:31:03,722 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 101
2015-10-24 03:31:03,722 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000099, cpktTxId=0000000000000000099)
2015-10-24 03:31:03,747 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 103 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-24 03:31:03,747 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 04:31:04,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 04:31:04,138 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=104&endTxId=105&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 04:31:04,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 04:31:04,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000104-0000000000000000105_0000000000439934989 size 0 bytes.
2015-10-24 04:31:04,143 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 04:31:04,143 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105 expecting start txid #104
2015-10-24 04:31:04,143 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105
2015-10-24 04:31:04,143 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000105 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 04:31:04,180 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 103
2015-10-24 04:31:04,180 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000101, cpktTxId=0000000000000000101)
2015-10-24 04:31:04,206 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 105 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-24 04:31:04,206 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 05:31:04,611 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 05:31:04,612 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=106&endTxId=107&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 05:31:04,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 05:31:04,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000106-0000000000000000107_0000000000443535462 size 0 bytes.
2015-10-24 05:31:04,616 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 05:31:04,616 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107 expecting start txid #106
2015-10-24 05:31:04,617 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107
2015-10-24 05:31:04,617 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000106-0000000000000000107 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 05:31:04,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 105
2015-10-24 05:31:04,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000103, cpktTxId=0000000000000000103)
2015-10-24 05:31:04,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 107 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-24 05:31:04,651 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 06:31:05,038 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 06:31:05,039 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=108&endTxId=109&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 06:31:05,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 06:31:05,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000108-0000000000000000109_0000000000447135889 size 0 bytes.
2015-10-24 06:31:05,043 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 06:31:05,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109 expecting start txid #108
2015-10-24 06:31:05,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109
2015-10-24 06:31:05,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000108-0000000000000000109 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 06:31:05,051 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 107
2015-10-24 06:31:05,051 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000105, cpktTxId=0000000000000000105)
2015-10-24 06:31:05,077 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 109 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-24 06:31:05,077 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 07:31:05,470 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 07:31:05,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=110&endTxId=111&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 07:31:05,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-24 07:31:05,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000110-0000000000000000111_0000000000450736321 size 0 bytes.
2015-10-24 07:31:05,503 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 07:31:05,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000111 expecting start txid #110
2015-10-24 07:31:05,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000111
2015-10-24 07:31:05,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000110-0000000000000000111 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 07:31:05,511 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 109
2015-10-24 07:31:05,511 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000107, cpktTxId=0000000000000000107)
2015-10-24 07:31:05,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 111 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-24 07:31:05,538 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 08:31:05,932 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 08:31:05,932 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=112&endTxId=113&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 08:31:05,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 08:31:05,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000112-0000000000000000113_0000000000454336783 size 0 bytes.
2015-10-24 08:31:05,937 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 08:31:05,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000112-0000000000000000113 expecting start txid #112
2015-10-24 08:31:05,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000112-0000000000000000113
2015-10-24 08:31:05,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000112-0000000000000000113 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 08:31:05,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 111
2015-10-24 08:31:05,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000109, cpktTxId=0000000000000000109)
2015-10-24 08:31:05,992 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 113 to namenode at http://master.hadoop:50070 in 0.026 seconds
2015-10-24 08:31:05,992 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 09:31:06,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 09:31:06,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=114&endTxId=115&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 09:31:06,384 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 09:31:06,384 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000114-0000000000000000115_0000000000457937231 size 0 bytes.
2015-10-24 09:31:06,385 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 09:31:06,385 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115 expecting start txid #114
2015-10-24 09:31:06,385 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115
2015-10-24 09:31:06,385 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000114-0000000000000000115 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 09:31:06,393 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 113
2015-10-24 09:31:06,393 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000111, cpktTxId=0000000000000000111)
2015-10-24 09:31:06,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 115 to namenode at http://master.hadoop:50070 in 0.018 seconds
2015-10-24 09:31:06,420 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 10:31:06,828 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 10:31:06,829 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=116&endTxId=117&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 10:31:06,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2015-10-24 10:31:06,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000116-0000000000000000117_0000000000461537679 size 0 bytes.
2015-10-24 10:31:06,870 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 10:31:06,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000117 expecting start txid #116
2015-10-24 10:31:06,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000117
2015-10-24 10:31:06,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000116-0000000000000000117 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 10:31:06,877 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 115
2015-10-24 10:31:06,877 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000113, cpktTxId=0000000000000000113)
2015-10-24 10:31:06,900 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 117 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-24 10:31:06,900 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 11:31:07,305 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 11:31:07,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=118&endTxId=119&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 11:31:07,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 11:31:07,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000118-0000000000000000119_0000000000465138156 size 0 bytes.
2015-10-24 11:31:07,312 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 11:31:07,313 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000118-0000000000000000119 expecting start txid #118
2015-10-24 11:31:07,313 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000118-0000000000000000119
2015-10-24 11:31:07,313 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000118-0000000000000000119 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 11:31:07,322 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 117
2015-10-24 11:31:07,322 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000115, cpktTxId=0000000000000000115)
2015-10-24 11:31:07,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 119 to namenode at http://master.hadoop:50070 in 0.034 seconds
2015-10-24 11:31:07,365 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 12:31:07,761 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 12:31:07,762 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=120&endTxId=121&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 12:31:07,770 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 12:31:07,770 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000120-0000000000000000121_0000000000468738612 size 0 bytes.
2015-10-24 12:31:07,771 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 12:31:07,771 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000120-0000000000000000121 expecting start txid #120
2015-10-24 12:31:07,771 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000120-0000000000000000121
2015-10-24 12:31:07,771 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000120-0000000000000000121 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 12:31:07,778 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 119
2015-10-24 12:31:07,779 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000117, cpktTxId=0000000000000000117)
2015-10-24 12:31:07,813 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 121 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-24 12:31:07,813 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 13:31:08,237 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 13:31:08,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=122&endTxId=123&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 13:31:08,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 13:31:08,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000122-0000000000000000123_0000000000472339089 size 0 bytes.
2015-10-24 13:31:08,243 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 13:31:08,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000122-0000000000000000123 expecting start txid #122
2015-10-24 13:31:08,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000122-0000000000000000123
2015-10-24 13:31:08,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000122-0000000000000000123 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 13:31:08,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 121
2015-10-24 13:31:08,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000119, cpktTxId=0000000000000000119)
2015-10-24 13:31:08,286 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 123 to namenode at http://master.hadoop:50070 in 0.026 seconds
2015-10-24 13:31:08,286 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 14:31:08,670 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 14:31:08,670 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=124&endTxId=125&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 14:31:08,674 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 14:31:08,674 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000124-0000000000000000125_0000000000475939521 size 0 bytes.
2015-10-24 14:31:08,675 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 14:31:08,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000124-0000000000000000125 expecting start txid #124
2015-10-24 14:31:08,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000124-0000000000000000125
2015-10-24 14:31:08,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000124-0000000000000000125 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 14:31:08,682 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 123
2015-10-24 14:31:08,683 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000121, cpktTxId=0000000000000000121)
2015-10-24 14:31:08,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 125 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-24 14:31:08,706 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 15:31:09,100 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 15:31:09,101 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=126&endTxId=127&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 15:31:09,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 15:31:09,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000126-0000000000000000127_0000000000479539951 size 0 bytes.
2015-10-24 15:31:09,105 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 15:31:09,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000126-0000000000000000127 expecting start txid #126
2015-10-24 15:31:09,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000126-0000000000000000127
2015-10-24 15:31:09,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000126-0000000000000000127 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 15:31:09,112 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 125
2015-10-24 15:31:09,112 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000123, cpktTxId=0000000000000000123)
2015-10-24 15:31:09,135 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 127 to namenode at http://master.hadoop:50070 in 0.014 seconds
2015-10-24 15:31:09,135 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 433
2015-10-24 16:31:09,537 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 16:31:09,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=128&endTxId=129&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 16:31:09,542 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 16:31:09,542 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000128-0000000000000000129_0000000000483140388 size 0 bytes.
2015-10-24 16:31:09,542 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 16:31:09,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000128-0000000000000000129 expecting start txid #128
2015-10-24 16:31:09,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000128-0000000000000000129
2015-10-24 16:31:09,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000128-0000000000000000129 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 16:31:09,553 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 127
2015-10-24 16:31:09,553 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000125, cpktTxId=0000000000000000125)
2015-10-24 16:31:09,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 129 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-24 16:31:09,578 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 17:31:09,958 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 17:31:09,958 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=130&endTxId=131&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 17:31:09,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 17:31:09,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000130-0000000000000000131_0000000000486740809 size 0 bytes.
2015-10-24 17:31:09,963 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 17:31:09,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000130-0000000000000000131 expecting start txid #130
2015-10-24 17:31:09,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000130-0000000000000000131
2015-10-24 17:31:09,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000130-0000000000000000131 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 17:31:09,971 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 129
2015-10-24 17:31:09,971 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000127, cpktTxId=0000000000000000127)
2015-10-24 17:31:09,996 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 131 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-24 17:31:09,996 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 18:31:10,385 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 18:31:10,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=132&endTxId=133&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 18:31:10,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 18:31:10,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000132-0000000000000000133_0000000000490341236 size 0 bytes.
2015-10-24 18:31:10,392 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 18:31:10,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000132-0000000000000000133 expecting start txid #132
2015-10-24 18:31:10,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000132-0000000000000000133
2015-10-24 18:31:10,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000132-0000000000000000133 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 18:31:10,400 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 131
2015-10-24 18:31:10,400 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000129, cpktTxId=0000000000000000129)
2015-10-24 18:31:10,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 133 to namenode at http://master.hadoop:50070 in 0.051 seconds
2015-10-24 18:31:10,461 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 19:31:10,852 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 19:31:10,853 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=134&endTxId=135&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 19:31:10,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 19:31:10,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000134-0000000000000000135_0000000000493941703 size 0 bytes.
2015-10-24 19:31:10,858 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 19:31:10,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000134-0000000000000000135 expecting start txid #134
2015-10-24 19:31:10,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000134-0000000000000000135
2015-10-24 19:31:10,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000134-0000000000000000135 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 19:31:10,866 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 133
2015-10-24 19:31:10,866 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000131, cpktTxId=0000000000000000131)
2015-10-24 19:31:10,893 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 135 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-24 19:31:10,893 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 20:31:11,291 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 20:31:11,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=136&endTxId=137&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 20:31:11,296 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 20:31:11,296 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000136-0000000000000000137_0000000000497542142 size 0 bytes.
2015-10-24 20:31:11,296 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 20:31:11,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000136-0000000000000000137 expecting start txid #136
2015-10-24 20:31:11,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000136-0000000000000000137
2015-10-24 20:31:11,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000136-0000000000000000137 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 20:31:11,304 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 135
2015-10-24 20:31:11,305 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000133, cpktTxId=0000000000000000133)
2015-10-24 20:31:11,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 137 to namenode at http://master.hadoop:50070 in 0.018 seconds
2015-10-24 20:31:11,332 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 21:31:11,715 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 21:31:11,715 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=138&endTxId=139&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 21:31:11,719 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 21:31:11,719 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000138-0000000000000000139_0000000000501142566 size 0 bytes.
2015-10-24 21:31:11,720 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 21:31:11,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000138-0000000000000000139 expecting start txid #138
2015-10-24 21:31:11,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000138-0000000000000000139
2015-10-24 21:31:11,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000138-0000000000000000139 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 21:31:11,728 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 137
2015-10-24 21:31:11,728 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000135, cpktTxId=0000000000000000135)
2015-10-24 21:31:11,774 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 139 to namenode at http://master.hadoop:50070 in 0.036 seconds
2015-10-24 21:31:11,774 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 22:31:12,156 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 22:31:12,156 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=140&endTxId=141&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 22:31:12,163 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 22:31:12,163 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000140-0000000000000000141_0000000000504743007 size 0 bytes.
2015-10-24 22:31:12,163 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 22:31:12,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000140-0000000000000000141 expecting start txid #140
2015-10-24 22:31:12,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000140-0000000000000000141
2015-10-24 22:31:12,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000140-0000000000000000141 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 22:31:12,176 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 139
2015-10-24 22:31:12,176 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000137, cpktTxId=0000000000000000137)
2015-10-24 22:31:12,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 141 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-24 22:31:12,220 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-24 23:31:12,618 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-24 23:31:12,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=142&endTxId=143&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-24 23:31:12,625 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-24 23:31:12,625 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000142-0000000000000000143_0000000000508343469 size 0 bytes.
2015-10-24 23:31:12,626 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-24 23:31:12,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000142-0000000000000000143 expecting start txid #142
2015-10-24 23:31:12,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000142-0000000000000000143
2015-10-24 23:31:12,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000142-0000000000000000143 of size 42 edits # 2 loaded in 0 seconds
2015-10-24 23:31:12,635 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 141
2015-10-24 23:31:12,635 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000139, cpktTxId=0000000000000000139)
2015-10-24 23:31:12,674 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 143 to namenode at http://master.hadoop:50070 in 0.018 seconds
2015-10-24 23:31:12,674 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 00:31:13,100 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 00:31:13,121 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=144&endTxId=145&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 00:31:13,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 00:31:13,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000144-0000000000000000145_0000000000511943972 size 0 bytes.
2015-10-25 00:31:13,131 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 00:31:13,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000144-0000000000000000145 expecting start txid #144
2015-10-25 00:31:13,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000144-0000000000000000145
2015-10-25 00:31:13,132 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000144-0000000000000000145 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 00:31:13,176 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 143
2015-10-25 00:31:13,176 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000141, cpktTxId=0000000000000000141)
2015-10-25 00:31:13,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 145 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 00:31:13,214 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 01:31:13,589 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 01:31:13,590 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=146&endTxId=147&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 01:31:13,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 01:31:13,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000146-0000000000000000147_0000000000515544440 size 0 bytes.
2015-10-25 01:31:13,594 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 01:31:13,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000146-0000000000000000147 expecting start txid #146
2015-10-25 01:31:13,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000146-0000000000000000147
2015-10-25 01:31:13,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000146-0000000000000000147 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 01:31:13,603 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 145
2015-10-25 01:31:13,603 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000143, cpktTxId=0000000000000000143)
2015-10-25 01:31:13,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 147 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 01:31:13,634 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 02:31:14,023 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 02:31:14,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=148&endTxId=149&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 02:31:14,030 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 02:31:14,030 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000148-0000000000000000149_0000000000519144874 size 0 bytes.
2015-10-25 02:31:14,030 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 02:31:14,030 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000148-0000000000000000149 expecting start txid #148
2015-10-25 02:31:14,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000148-0000000000000000149
2015-10-25 02:31:14,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000148-0000000000000000149 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 02:31:14,038 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 147
2015-10-25 02:31:14,038 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000145, cpktTxId=0000000000000000145)
2015-10-25 02:31:14,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 149 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-25 02:31:14,065 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 03:31:14,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 03:31:14,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=150&endTxId=151&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 03:31:14,486 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-25 03:31:14,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000150-0000000000000000151_0000000000522745302 size 0 bytes.
2015-10-25 03:31:14,487 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 03:31:14,487 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000150-0000000000000000151 expecting start txid #150
2015-10-25 03:31:14,487 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000150-0000000000000000151
2015-10-25 03:31:14,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000150-0000000000000000151 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 03:31:14,495 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 149
2015-10-25 03:31:14,495 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000147, cpktTxId=0000000000000000147)
2015-10-25 03:31:14,520 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 151 to namenode at http://master.hadoop:50070 in 0.015 seconds
2015-10-25 03:31:14,521 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 04:31:14,904 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 04:31:14,905 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=152&endTxId=153&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 04:31:14,909 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 04:31:14,909 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000152-0000000000000000153_0000000000526345755 size 0 bytes.
2015-10-25 04:31:14,909 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 04:31:14,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000152-0000000000000000153 expecting start txid #152
2015-10-25 04:31:14,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000152-0000000000000000153
2015-10-25 04:31:14,910 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000152-0000000000000000153 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 04:31:14,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 151
2015-10-25 04:31:14,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000149, cpktTxId=0000000000000000149)
2015-10-25 04:31:14,944 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 153 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 04:31:14,944 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 05:31:15,332 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 05:31:15,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=154&endTxId=155&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 05:31:15,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 05:31:15,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000154-0000000000000000155_0000000000529946183 size 0 bytes.
2015-10-25 05:31:15,337 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 05:31:15,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000154-0000000000000000155 expecting start txid #154
2015-10-25 05:31:15,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000154-0000000000000000155
2015-10-25 05:31:15,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000154-0000000000000000155 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 05:31:15,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 153
2015-10-25 05:31:15,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000151, cpktTxId=0000000000000000151)
2015-10-25 05:31:15,372 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 155 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 05:31:15,373 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 06:31:15,754 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 06:31:15,754 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=156&endTxId=157&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 06:31:15,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-10-25 06:31:15,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000156-0000000000000000157_0000000000533546605 size 0 bytes.
2015-10-25 06:31:15,788 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 06:31:15,788 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000156-0000000000000000157 expecting start txid #156
2015-10-25 06:31:15,788 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000156-0000000000000000157
2015-10-25 06:31:15,789 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000156-0000000000000000157 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 06:31:15,796 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 155
2015-10-25 06:31:15,796 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000153, cpktTxId=0000000000000000153)
2015-10-25 06:31:15,822 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 157 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 06:31:15,822 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 07:31:16,220 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 07:31:16,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=158&endTxId=159&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 07:31:16,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-25 07:31:16,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000158-0000000000000000159_0000000000537147071 size 0 bytes.
2015-10-25 07:31:16,232 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 07:31:16,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000158-0000000000000000159 expecting start txid #158
2015-10-25 07:31:16,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000158-0000000000000000159
2015-10-25 07:31:16,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000158-0000000000000000159 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 07:31:16,240 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 157
2015-10-25 07:31:16,240 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000155, cpktTxId=0000000000000000155)
2015-10-25 07:31:16,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 159 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 07:31:16,268 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 08:31:16,666 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 08:31:16,666 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=160&endTxId=161&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 08:31:16,675 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 08:31:16,675 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000160-0000000000000000161_0000000000540747517 size 0 bytes.
2015-10-25 08:31:16,675 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 08:31:16,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000160-0000000000000000161 expecting start txid #160
2015-10-25 08:31:16,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000160-0000000000000000161
2015-10-25 08:31:16,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000160-0000000000000000161 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 08:31:16,688 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 159
2015-10-25 08:31:16,688 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000157, cpktTxId=0000000000000000157)
2015-10-25 08:31:16,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 161 to namenode at http://master.hadoop:50070 in 0.027 seconds
2015-10-25 08:31:16,727 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 09:31:17,154 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 09:31:17,155 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=162&endTxId=163&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 09:31:17,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 09:31:17,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000162-0000000000000000163_0000000000544348005 size 0 bytes.
2015-10-25 09:31:17,162 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 09:31:17,162 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000162-0000000000000000163 expecting start txid #162
2015-10-25 09:31:17,162 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000162-0000000000000000163
2015-10-25 09:31:17,162 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000162-0000000000000000163 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 09:31:17,170 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 161
2015-10-25 09:31:17,170 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000159, cpktTxId=0000000000000000159)
2015-10-25 09:31:17,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 163 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 09:31:17,203 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 10:31:17,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 10:31:17,590 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=164&endTxId=165&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 10:31:17,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 10:31:17,594 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000164-0000000000000000165_0000000000547948441 size 0 bytes.
2015-10-25 10:31:17,594 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 10:31:17,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000164-0000000000000000165 expecting start txid #164
2015-10-25 10:31:17,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000164-0000000000000000165
2015-10-25 10:31:17,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000164-0000000000000000165 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 10:31:17,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 163
2015-10-25 10:31:17,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000161, cpktTxId=0000000000000000161)
2015-10-25 10:31:17,628 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 165 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 10:31:17,628 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 11:31:18,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 11:31:18,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=166&endTxId=167&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 11:31:18,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 11:31:18,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000166-0000000000000000167_0000000000551548867 size 0 bytes.
2015-10-25 11:31:18,021 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 11:31:18,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000166-0000000000000000167 expecting start txid #166
2015-10-25 11:31:18,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000166-0000000000000000167
2015-10-25 11:31:18,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000166-0000000000000000167 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 11:31:18,030 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 165
2015-10-25 11:31:18,030 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000163, cpktTxId=0000000000000000163)
2015-10-25 11:31:18,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 167 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 11:31:18,058 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 12:31:18,460 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 12:31:18,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=168&endTxId=169&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 12:31:18,464 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 12:31:18,464 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000168-0000000000000000169_0000000000555149311 size 0 bytes.
2015-10-25 12:31:18,465 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 12:31:18,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000168-0000000000000000169 expecting start txid #168
2015-10-25 12:31:18,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000168-0000000000000000169
2015-10-25 12:31:18,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000168-0000000000000000169 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 12:31:18,472 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 167
2015-10-25 12:31:18,472 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000165, cpktTxId=0000000000000000165)
2015-10-25 12:31:18,500 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 169 to namenode at http://master.hadoop:50070 in 0.016 seconds
2015-10-25 12:31:18,500 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 13:31:18,899 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 13:31:18,899 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=170&endTxId=171&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 13:31:18,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 13:31:18,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000170-0000000000000000171_0000000000558749750 size 0 bytes.
2015-10-25 13:31:18,903 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 13:31:18,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000170-0000000000000000171 expecting start txid #170
2015-10-25 13:31:18,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000170-0000000000000000171
2015-10-25 13:31:18,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000170-0000000000000000171 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 13:31:18,912 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 169
2015-10-25 13:31:18,912 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000167, cpktTxId=0000000000000000167)
2015-10-25 13:31:18,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 171 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 13:31:18,942 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 14:31:19,332 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 14:31:19,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=172&endTxId=173&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 14:31:19,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 14:31:19,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000172-0000000000000000173_0000000000562350183 size 0 bytes.
2015-10-25 14:31:19,336 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 14:31:19,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000172-0000000000000000173 expecting start txid #172
2015-10-25 14:31:19,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000172-0000000000000000173
2015-10-25 14:31:19,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000172-0000000000000000173 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 14:31:19,344 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 171
2015-10-25 14:31:19,344 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000169, cpktTxId=0000000000000000169)
2015-10-25 14:31:19,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 173 to namenode at http://master.hadoop:50070 in 0.046 seconds
2015-10-25 14:31:19,411 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 15:31:19,796 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 15:31:19,797 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=174&endTxId=175&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 15:31:19,801 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 15:31:19,801 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000174-0000000000000000175_0000000000565950647 size 0 bytes.
2015-10-25 15:31:19,801 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 15:31:19,801 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000174-0000000000000000175 expecting start txid #174
2015-10-25 15:31:19,801 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000174-0000000000000000175
2015-10-25 15:31:19,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000174-0000000000000000175 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 15:31:19,809 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 173
2015-10-25 15:31:19,809 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000171, cpktTxId=0000000000000000171)
2015-10-25 15:31:19,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 175 to namenode at http://master.hadoop:50070 in 0.022 seconds
2015-10-25 15:31:19,843 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 16:31:20,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 16:31:20,221 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=176&endTxId=177&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 16:31:20,231 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 16:31:20,231 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000176-0000000000000000177_0000000000569551072 size 0 bytes.
2015-10-25 16:31:20,231 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 16:31:20,231 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000176-0000000000000000177 expecting start txid #176
2015-10-25 16:31:20,231 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000176-0000000000000000177
2015-10-25 16:31:20,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000176-0000000000000000177 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 16:31:20,243 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 175
2015-10-25 16:31:20,244 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000173, cpktTxId=0000000000000000173)
2015-10-25 16:31:20,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 177 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 16:31:20,274 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 17:31:20,658 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 17:31:20,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=178&endTxId=179&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 17:31:20,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 17:31:20,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000178-0000000000000000179_0000000000573151509 size 0 bytes.
2015-10-25 17:31:20,665 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 17:31:20,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000178-0000000000000000179 expecting start txid #178
2015-10-25 17:31:20,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000178-0000000000000000179
2015-10-25 17:31:20,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000178-0000000000000000179 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 17:31:20,673 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 177
2015-10-25 17:31:20,673 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000175, cpktTxId=0000000000000000175)
2015-10-25 17:31:20,733 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 179 to namenode at http://master.hadoop:50070 in 0.048 seconds
2015-10-25 17:31:20,733 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 18:31:21,122 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 18:31:21,122 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=180&endTxId=181&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 18:31:21,126 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 18:31:21,126 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000180-0000000000000000181_0000000000576751972 size 0 bytes.
2015-10-25 18:31:21,126 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 18:31:21,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000180-0000000000000000181 expecting start txid #180
2015-10-25 18:31:21,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000180-0000000000000000181
2015-10-25 18:31:21,127 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000180-0000000000000000181 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 18:31:21,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 179
2015-10-25 18:31:21,135 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000177, cpktTxId=0000000000000000177)
2015-10-25 18:31:21,164 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 181 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 18:31:21,164 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 19:31:21,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 19:31:21,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=182&endTxId=183&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 19:31:21,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 19:31:21,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000182-0000000000000000183_0000000000580352402 size 0 bytes.
2015-10-25 19:31:21,556 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 19:31:21,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000182-0000000000000000183 expecting start txid #182
2015-10-25 19:31:21,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000182-0000000000000000183
2015-10-25 19:31:21,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000182-0000000000000000183 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 19:31:21,564 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 181
2015-10-25 19:31:21,564 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000179, cpktTxId=0000000000000000179)
2015-10-25 19:31:21,592 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 183 to namenode at http://master.hadoop:50070 in 0.017 seconds
2015-10-25 19:31:21,592 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 20:31:22,001 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 20:31:22,001 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=184&endTxId=185&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 20:31:22,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 20:31:22,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000184-0000000000000000185_0000000000583952852 size 0 bytes.
2015-10-25 20:31:22,005 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 20:31:22,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000184-0000000000000000185 expecting start txid #184
2015-10-25 20:31:22,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000184-0000000000000000185
2015-10-25 20:31:22,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000184-0000000000000000185 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 20:31:22,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 183
2015-10-25 20:31:22,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000181, cpktTxId=0000000000000000181)
2015-10-25 20:31:22,085 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 185 to namenode at http://master.hadoop:50070 in 0.02 seconds
2015-10-25 20:31:22,085 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 21:31:22,472 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 21:31:22,472 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=186&endTxId=187&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 21:31:22,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 21:31:22,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000186-0000000000000000187_0000000000587553323 size 0 bytes.
2015-10-25 21:31:22,476 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 21:31:22,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000186-0000000000000000187 expecting start txid #186
2015-10-25 21:31:22,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000186-0000000000000000187
2015-10-25 21:31:22,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000186-0000000000000000187 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 21:31:22,484 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 185
2015-10-25 21:31:22,484 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000183, cpktTxId=0000000000000000183)
2015-10-25 21:31:22,516 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 187 to namenode at http://master.hadoop:50070 in 0.018 seconds
2015-10-25 21:31:22,516 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 22:31:22,901 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 22:31:22,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=188&endTxId=189&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 22:31:22,905 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 22:31:22,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000188-0000000000000000189_0000000000591153752 size 0 bytes.
2015-10-25 22:31:22,906 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 22:31:22,906 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000188-0000000000000000189 expecting start txid #188
2015-10-25 22:31:22,906 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000188-0000000000000000189
2015-10-25 22:31:22,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000188-0000000000000000189 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 22:31:22,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 187
2015-10-25 22:31:22,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000185, cpktTxId=0000000000000000185)
2015-10-25 22:31:22,943 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 189 to namenode at http://master.hadoop:50070 in 0.018 seconds
2015-10-25 22:31:22,944 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-25 23:31:23,358 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-25 23:31:23,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=190&endTxId=191&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-25 23:31:23,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-25 23:31:23,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000190-0000000000000000191_0000000000594754209 size 0 bytes.
2015-10-25 23:31:23,363 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-25 23:31:23,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000190-0000000000000000191 expecting start txid #190
2015-10-25 23:31:23,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000190-0000000000000000191
2015-10-25 23:31:23,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000190-0000000000000000191 of size 42 edits # 2 loaded in 0 seconds
2015-10-25 23:31:23,372 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 189
2015-10-25 23:31:23,372 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000187, cpktTxId=0000000000000000187)
2015-10-25 23:31:23,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 191 to namenode at http://master.hadoop:50070 in 0.02 seconds
2015-10-25 23:31:23,403 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-26 00:31:23,787 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-26 00:31:23,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=192&endTxId=193&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-26 00:31:23,794 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-10-26 00:31:23,794 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000192-0000000000000000193_0000000000598354638 size 0 bytes.
2015-10-26 00:31:23,794 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-26 00:31:23,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000192-0000000000000000193 expecting start txid #192
2015-10-26 00:31:23,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000192-0000000000000000193
2015-10-26 00:31:23,795 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000192-0000000000000000193 of size 42 edits # 2 loaded in 0 seconds
2015-10-26 00:31:23,802 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 191
2015-10-26 00:31:23,802 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000189, cpktTxId=0000000000000000189)
2015-10-26 00:31:23,843 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 193 to namenode at http://master.hadoop:50070 in 0.028 seconds
2015-10-26 00:31:23,843 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
2015-10-26 01:31:24,267 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-10-26 01:31:24,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master.hadoop:50070/imagetransfer?getedit=1&startTxId=194&endTxId=195&storageInfo=-57:1240493319:0:CID-f4c5d5b1-ac79-4290-9a6c-377b5c7521eb
2015-10-26 01:31:24,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-10-26 01:31:24,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000194-0000000000000000195_0000000000601955118 size 0 bytes.
2015-10-26 01:31:24,279 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-10-26 01:31:24,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000194-0000000000000000195 expecting start txid #194
2015-10-26 01:31:24,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000194-0000000000000000195
2015-10-26 01:31:24,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/edits_0000000000000000194-0000000000000000195 of size 42 edits # 2 loaded in 0 seconds
2015-10-26 01:31:24,287 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 193
2015-10-26 01:31:24,287 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/sihhuang/hadoop/hadoop-sihhuang/dfs/namesecondary/current/fsimage_0000000000000000191, cpktTxId=0000000000000000191)
2015-10-26 01:31:24,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 195 to namenode at http://master.hadoop:50070 in 0.027 seconds
2015-10-26 01:31:24,332 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 434
